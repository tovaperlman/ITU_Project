{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Images/ cropped.jpg css/ style.css","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files. Images/ cropped.jpg css/ style.css","title":"Project layout"},{"location":"about/","text":"This is about our project with ITU. Who are we? Tova Perlman Utku Can Ozturk Jonathan Cook Jacob Beck Project Mentor: Daniel Townsend Technical Mentor: Robert Hager Who is ITU? Who is UNICEF? What is Project Giga?","title":"About the Team"},{"location":"conc/","text":"Discussion We have gained a variety of insights that can be used in future research and extension of the analyses. While our technical and methodological learnings have been outlined in the previous sections, the following conclusion will briefly provide an outcome interpretation of the project and then discuss limitations and possible next steps. Outcome Interpretation We have developed a tool that is capable of providing multiple outcomes. First of all, after model application a prioritizing list of school within a country can be created. The priorization can be sorted by absolute number of offline population potentially served or by relative share of online population. In addition, it is possible to adapt the listing e.g. by excluding densely populated areas in order to get a list of schools in lowly populated areas, that would benefit most from internet connection. Moreover, the level of geographic aggregation of connectivity ratio can be modified up to federal state or full country level. Our provided scripts in combination with the documentation can now assist institutions like Giga Initiative to manage resource allocation for connecting schools. This can be done within a country, between multiple countries and potentially on province, region or city level. Aside from that we have created a straight-forward tool for feature data gathering and EDA. Creating simple map graphics or correlation plots might already indicate the presence of clear tendencies. Limitations During our project we have faced limitations especially in the area of model evaluation. The results make sense within our model and data, however it is yet to determine how this transfers to reality. Future extension and application of our models can help to further evaluate our project outcome. In the special case of Thailand another problem became obvious: The used data inherited multiple sources of error, therefore it was not possible to separate these from each other. In this specific case, for instance, we could not find out to which degree the geographic aggregation of the target variable or the fact that we used OSM schools impacted model performance and error. In addition to the limitations we faced, there are more limitations that could possibly be present in our work as well as in future extensions. As touched upon previously, we cannot evaluate yet how OSM school data performs compared to official school location data. If this datasource is supposed to be a cost and resource efficient replacement for UNICEF school data, its representativity should be reviewed. Furthermore, Facebook data could inherit an \"instability\" of how to interpret the feature. If popularity of Facebook differs over time, between countries or according to demographic indicators utilization does not remain straight forward. When examining feature importances and impacts, larger number of Facebook users have generally led to higher predictions of online population. However, if a big internationalized metropolitan area (e.g. Buenos Aires) shows a low percentage of Facebook users, this could much rather be due to the fact that another social media platform (such as Instagram) has overtaken the popularity. An analysis of dispersion of Facebook users among social strata could prevent a misinterpretation of data. Another potential source of bias could be the fact, that in our approach survey data is used as ground truth. Survey data are typically prone for biasing mechanisms like misreport or systematic non-response. Survey respondents have previously stated that they are not using the internet but in the same survey declared themselves as internet users. Non-response could be problematic if offline people tend to respond to the survey less likely. A potential corroborrating measure here could be comparing the distribution of demographic data within the survey (e.g income, gender) with other open (official) data sources. Ultimately, if the analyses will be extended to more countries the availability of microdata could bias the selection of countries that will be targeted. One could assume, that countries where no microdata on telecommunications exists could as well be countries with low connectivity. Further research should attempt to not disregard low connected countries systematically and potentially aim for a full open source data approach. Next Steps Additional Methods Multiple additional methods could be applied to our existing models and analyses: Full scoring on Brazil Given our existing champion model, all schools outside the featured enumeration areas can now be scored with an estimated level of connectivtiy. This could be done for a sample of schools as a sanity check or for entire Brazil, which would yield a similar map like the Giga Initiative connectivtiy map. Statistical robustness checks Especially two steps could be reasonable additions that take the geographic nature of the data into account: Estimating a Geographically Weighted Regression (GWR) and performing spatial cross-validation on the models. Experiment with featured data The manner in which we used some of the features could be varied. First of all, it could be fruitful to experiment with Facebook data. It might occur, that Facebook data already suffices as a standalone proxy variable for online population. Hypothetically this would decrease the need for model estimation and enable a global extension of the project. Furthermore, pulling OSM school locations for Brazil and applying the model to this sample could yield insights on the representativity of OSM data. Lastly, buffer zones around schools are currently constant in diameter, but could be varied according to specific variables (e.g. population data). Extension on other countries The existing model can be applied to every country, with OSM school location data available. However,model evaluation or model training for other countries requires two more components: Microdata (on household, individual or enumeration area level) and the respective shapefiles/geolocation of the enumeration area. Our analyses have indicated, that analyzing larger geographical aggregates like provinces diminishes model performance and interpretability. An enumeration area is assumed to be a largely homogeneous area, whereas the variation of connectivtiy within e.g. a federal state should be much higher. Further model training With more countries being included to the connectivity analysis, more options of model combinations open up. Given the requirements are met, an individual model can be trained for each country and evaluated separately. In addition, joint models with multiple countries could result in a high predictive power on a global level and increase model robustness. Comparing the performances of combined and single-country models can give insights on the impact of country specific differences. Furthermore, it might be a reasonable idea to train regional models (e.g. a model for South East Asian countries). Actors that are not able to provide enumeration area level microdata (e.g. due to anonymity restrictions) can obtain our provided scripts and additional content and run a custom model training. Additional data sources Country-level data When extending the models on multiple countries, it might make sense to include country level variables. Possbile additions could be urbanization rate, GDP, public spendings on telecommunications or other indices of human/infrastructural development. In doing so, \"country-specific intercepts\" are featured in the estimation and will assist accounting for differences in overall connectivtiy between countries. Additional content from survey/school data The original models we provide have so far only been utilizing the necessarily required features of survey and school data. Too keep our approach as reproducible as possible for many countries we have so far asbtained from using additional information within these data sources. However, usually the survey will contain more connectivity-related variables and items such as more survey questions on telecommunications (e.g reasons for (non-)connectivity), demographic information such as age or gender or information on household size or income. Similarly information in school location data such as pupil count or computer availability could potentially be used in further analyses, e.g. when trying to estimate the feasability of connection for a specific school. Further data Existing models could supposedly be improved by adding more features to the training data. Possible additions could stem from official data provided by ministries/regulators, platform/network/monitoring services like Google, Facebook or Cisco Analytics or (coverage) telecommunication data from telecommunication companies and operators. Nevertheless, at minimum a hypothetical logical connection between feature and target variable should always be existent. Our project goal was to improve understanding of predicting the world's offline population which we have examined in three case studies in Brazil, Thailand and the Philippines. In doing so we have created tools, that can be used by researchers and institutions to investigate in the connectivity within a country and do national and regional comparisons. This documentation is supposed to be a guidance for reproduction and extension of the project outcome.","title":"Discussion"},{"location":"conc/#discussion","text":"We have gained a variety of insights that can be used in future research and extension of the analyses. While our technical and methodological learnings have been outlined in the previous sections, the following conclusion will briefly provide an outcome interpretation of the project and then discuss limitations and possible next steps.","title":"Discussion"},{"location":"conc/#outcome-interpretation","text":"We have developed a tool that is capable of providing multiple outcomes. First of all, after model application a prioritizing list of school within a country can be created. The priorization can be sorted by absolute number of offline population potentially served or by relative share of online population. In addition, it is possible to adapt the listing e.g. by excluding densely populated areas in order to get a list of schools in lowly populated areas, that would benefit most from internet connection. Moreover, the level of geographic aggregation of connectivity ratio can be modified up to federal state or full country level. Our provided scripts in combination with the documentation can now assist institutions like Giga Initiative to manage resource allocation for connecting schools. This can be done within a country, between multiple countries and potentially on province, region or city level. Aside from that we have created a straight-forward tool for feature data gathering and EDA. Creating simple map graphics or correlation plots might already indicate the presence of clear tendencies.","title":"Outcome Interpretation"},{"location":"conc/#limitations","text":"During our project we have faced limitations especially in the area of model evaluation. The results make sense within our model and data, however it is yet to determine how this transfers to reality. Future extension and application of our models can help to further evaluate our project outcome. In the special case of Thailand another problem became obvious: The used data inherited multiple sources of error, therefore it was not possible to separate these from each other. In this specific case, for instance, we could not find out to which degree the geographic aggregation of the target variable or the fact that we used OSM schools impacted model performance and error. In addition to the limitations we faced, there are more limitations that could possibly be present in our work as well as in future extensions. As touched upon previously, we cannot evaluate yet how OSM school data performs compared to official school location data. If this datasource is supposed to be a cost and resource efficient replacement for UNICEF school data, its representativity should be reviewed. Furthermore, Facebook data could inherit an \"instability\" of how to interpret the feature. If popularity of Facebook differs over time, between countries or according to demographic indicators utilization does not remain straight forward. When examining feature importances and impacts, larger number of Facebook users have generally led to higher predictions of online population. However, if a big internationalized metropolitan area (e.g. Buenos Aires) shows a low percentage of Facebook users, this could much rather be due to the fact that another social media platform (such as Instagram) has overtaken the popularity. An analysis of dispersion of Facebook users among social strata could prevent a misinterpretation of data. Another potential source of bias could be the fact, that in our approach survey data is used as ground truth. Survey data are typically prone for biasing mechanisms like misreport or systematic non-response. Survey respondents have previously stated that they are not using the internet but in the same survey declared themselves as internet users. Non-response could be problematic if offline people tend to respond to the survey less likely. A potential corroborrating measure here could be comparing the distribution of demographic data within the survey (e.g income, gender) with other open (official) data sources. Ultimately, if the analyses will be extended to more countries the availability of microdata could bias the selection of countries that will be targeted. One could assume, that countries where no microdata on telecommunications exists could as well be countries with low connectivity. Further research should attempt to not disregard low connected countries systematically and potentially aim for a full open source data approach.","title":"Limitations"},{"location":"conc/#next-steps","text":"","title":"Next Steps"},{"location":"conc/#additional-methods","text":"Multiple additional methods could be applied to our existing models and analyses: Full scoring on Brazil Given our existing champion model, all schools outside the featured enumeration areas can now be scored with an estimated level of connectivtiy. This could be done for a sample of schools as a sanity check or for entire Brazil, which would yield a similar map like the Giga Initiative connectivtiy map. Statistical robustness checks Especially two steps could be reasonable additions that take the geographic nature of the data into account: Estimating a Geographically Weighted Regression (GWR) and performing spatial cross-validation on the models. Experiment with featured data The manner in which we used some of the features could be varied. First of all, it could be fruitful to experiment with Facebook data. It might occur, that Facebook data already suffices as a standalone proxy variable for online population. Hypothetically this would decrease the need for model estimation and enable a global extension of the project. Furthermore, pulling OSM school locations for Brazil and applying the model to this sample could yield insights on the representativity of OSM data. Lastly, buffer zones around schools are currently constant in diameter, but could be varied according to specific variables (e.g. population data).","title":"Additional Methods"},{"location":"conc/#extension-on-other-countries","text":"The existing model can be applied to every country, with OSM school location data available. However,model evaluation or model training for other countries requires two more components: Microdata (on household, individual or enumeration area level) and the respective shapefiles/geolocation of the enumeration area. Our analyses have indicated, that analyzing larger geographical aggregates like provinces diminishes model performance and interpretability. An enumeration area is assumed to be a largely homogeneous area, whereas the variation of connectivtiy within e.g. a federal state should be much higher.","title":"Extension on other countries"},{"location":"conc/#further-model-training","text":"With more countries being included to the connectivity analysis, more options of model combinations open up. Given the requirements are met, an individual model can be trained for each country and evaluated separately. In addition, joint models with multiple countries could result in a high predictive power on a global level and increase model robustness. Comparing the performances of combined and single-country models can give insights on the impact of country specific differences. Furthermore, it might be a reasonable idea to train regional models (e.g. a model for South East Asian countries). Actors that are not able to provide enumeration area level microdata (e.g. due to anonymity restrictions) can obtain our provided scripts and additional content and run a custom model training.","title":"Further model training"},{"location":"conc/#additional-data-sources","text":"Country-level data When extending the models on multiple countries, it might make sense to include country level variables. Possbile additions could be urbanization rate, GDP, public spendings on telecommunications or other indices of human/infrastructural development. In doing so, \"country-specific intercepts\" are featured in the estimation and will assist accounting for differences in overall connectivtiy between countries. Additional content from survey/school data The original models we provide have so far only been utilizing the necessarily required features of survey and school data. Too keep our approach as reproducible as possible for many countries we have so far asbtained from using additional information within these data sources. However, usually the survey will contain more connectivity-related variables and items such as more survey questions on telecommunications (e.g reasons for (non-)connectivity), demographic information such as age or gender or information on household size or income. Similarly information in school location data such as pupil count or computer availability could potentially be used in further analyses, e.g. when trying to estimate the feasability of connection for a specific school. Further data Existing models could supposedly be improved by adding more features to the training data. Possible additions could stem from official data provided by ministries/regulators, platform/network/monitoring services like Google, Facebook or Cisco Analytics or (coverage) telecommunication data from telecommunication companies and operators. Nevertheless, at minimum a hypothetical logical connection between feature and target variable should always be existent. Our project goal was to improve understanding of predicting the world's offline population which we have examined in three case studies in Brazil, Thailand and the Philippines. In doing so we have created tools, that can be used by researchers and institutions to investigate in the connectivity within a country and do national and regional comparisons. This documentation is supposed to be a guidance for reproduction and extension of the project outcome.","title":"Additional data sources"},{"location":"configs/","text":"Configurations We use configs.py to store the variable configurations that should be changed according to use-case: WD - Working Directory, e.g. '../../../files/' AVAILABLE_COUNTRIES - Countries for which survey data with an internet connectivity ground truth variable is available, e.g. list('bra', 'tha') COUNTRY - Country code for current use-case, e.g. 'tha' FEATURES - List of predictive features for use-case, e.g. list('speedtest', 'opencell', 'facebook', 'population', 'satellite'). This exemplary list contains each of the five open data sources we have used and they must be sytactically entered as shown.","title":"Configurations"},{"location":"configs/#configurations","text":"We use configs.py to store the variable configurations that should be changed according to use-case: WD - Working Directory, e.g. '../../../files/' AVAILABLE_COUNTRIES - Countries for which survey data with an internet connectivity ground truth variable is available, e.g. list('bra', 'tha') COUNTRY - Country code for current use-case, e.g. 'tha' FEATURES - List of predictive features for use-case, e.g. list('speedtest', 'opencell', 'facebook', 'population', 'satellite'). This exemplary list contains each of the five open data sources we have used and they must be sytactically entered as shown.","title":"Configurations"},{"location":"data_dictionaries/","text":"Data Dictionaries Data dictionaries should be created for each predictor and survey dataset. Dictionaries for the open-source data and Brazilian, Thai and Philippino survey data already exist and should be located in the data/meta/ folder. An exemplary data dictionary (for speedtest data) is shown below: Number Name Description Type Binary Role Use Comment 1 avg_d_kbps The average download speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 2 avg_u_kbps The average upload speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 3 avg_lat_ms The average latency of all tests performed in the tile, represented in milliseconds num N predictor N 4 tests The number of tests taken in the tile num N predictor N 5 devices The number of unique devices contributing tests in the tile num N predictor N","title":"Data Dictionaries"},{"location":"data_dictionaries/#data-dictionaries","text":"Data dictionaries should be created for each predictor and survey dataset. Dictionaries for the open-source data and Brazilian, Thai and Philippino survey data already exist and should be located in the data/meta/ folder. An exemplary data dictionary (for speedtest data) is shown below: Number Name Description Type Binary Role Use Comment 1 avg_d_kbps The average download speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 2 avg_u_kbps The average upload speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 3 avg_lat_ms The average latency of all tests performed in the tile, represented in milliseconds num N predictor N 4 tests The number of tests taken in the tile num N predictor N 5 devices The number of unique devices contributing tests in the tile num N predictor N","title":"Data Dictionaries"},{"location":"data_processing/","text":"Instructions to Create Model-Ready Dataset To generate a dataframe comprising any target variables and predictors that you wish to use, first set up the use-case configurations in configs.py. Details of the configurable variables and their expected assignments can be found in the 'configurations' section of the documentation. Having correctly set the desired configurations, all you need to do is run 'main.py'. Following this, a dataset for model training and/or application will be saved within a training_sets folder, which is situated within the data directory.","title":"Data Processing Guide"},{"location":"data_processing/#instructions-to-create-model-ready-dataset","text":"To generate a dataframe comprising any target variables and predictors that you wish to use, first set up the use-case configurations in configs.py. Details of the configurable variables and their expected assignments can be found in the 'configurations' section of the documentation. Having correctly set the desired configurations, all you need to do is run 'main.py'. Following this, a dataset for model training and/or application will be saved within a training_sets folder, which is situated within the data directory.","title":"Instructions to Create Model-Ready Dataset"},{"location":"datagat/","text":"mermaid.initialize({startOnLoad:true}); mermaidAPI.initialize({ securityLevel: 'loose' }); Data Gathering Utku did a lot of work on this. Yay Utku!! Internal Data Surveys from ITU for Brazil and Thailand The target variable for our modeling was the proportion of a population around a particular school that was connected to the internet. It therefore ranged from 0-1, with 0 being zero percent connected and 100 being 100% connected to the internet. We chose to measure this on a school level as one of our objectives, through working with UNICEF, was to detect schools that could be connected to the internet and further serve the community they are located. Within the Brazil Survey data, we received information on household internet connectivity on an enumeration area level. This presented a slight challenge as the level of granularity of the school data was slightly different from the enumeration data or census tract. Thus, we matched the school points to the enumeration area data. We could not use all the school points as we only had enumeration areas for a specific amount of tracts in Brazil. Thus we had to subset our school points data to around 11,000 points. Once we connected the schools to the enumeration areas we were able to build our training data set. School Points from UNICEF for Brazil We got the school points in lat, long format from UNICEF for Brazil. Unfortunately, we were not able to obtain the school points for Thailand. We thus turned to OpenStreetMap to obtain school points for Thailand. We obtained many school points but filtered them to the schools that we were positive were schools as some were tagged as dance schools or even ATM's. Our school points script is thus specific for obtaining the OSM points. Should we say something about the licensing? External/Open Source Data We now have to gather all the open data that we've used: Open Cell ID School Population Points using OSM Satellite data To see the full code for gathering this data, click here. To gather the satellite data, we used Google Earth Engine for Python API. We gathered three different types of data: Global Human Modification Index, Nighttime Data, Normalized Difference Vegetation Index. Our hope with gathering this data is that it would provide an accurate proxy for households and schools with internet connection. If we knew a school was located in a place with a high average radiance, it might also mean there was high internet connectivity. The beauty of satellite data is that its continous for the entire globe. We initially struggled with learning how to crop the data for all the school points we wanted. Eventually, we set a 5 km buffer zone around each school point in both Brazil and Thailand and obtained specific satellite information that was input as a number into the training dataset. Below please find more information on each of the datasets we used. Global Human Modification Index (String for Image Collection ID is: 'CSP/HM/GlobalHumanModification'): The global Human Modification dataset (gHM) provides a cumulative measure of human modification of terrestrial lands globally at 1 square-kilometer resolution. The gHM values range from 0.0-1.0 and are calculated by estimating the proportion of a given location (pixel) that is modified, the estimated intensity of modification associated with a given type of human modification or \"stressor\". 5 major anthropogenic stressors circa 2016 were mapped using 13 individual datasets: human settlement (population density, built-up areas) agriculture (cropland, livestock) transportation (major, minor, and two-track roads; railroads) mining and energy production electrical infrastructure (power lines, nighttime lights) NOAA Monthly Nighttime images using the VIIRS Satellite (String for Image Collection ID is: \"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\") Monthly average radiance composite images using nighttime data from the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB). As these data are composited monthly, there are many areas of the globe where it is impossible to get good quality data coverage for that month. This can be due to cloud cover, especially in the tropical regions, or due to solar illumination, as happens toward the poles in their respective summer months. Therefore it is recommended that users of these data utilize the 'cf_cvg' band and not assume a value of zero in the average radiance image means that no lights were observed. Normalized Difference Vegetation Index Band from the MODIS dataset (String for Image Collection ID is: 'MODIS/006/MOD13A2'): Normalized Difference Vegetation Index or NDVI measures the vegetation or greenness present on the Earth's surface The algorithm for this product chooses the best available pixel value from all the acquisitions from the 16-day period. The criteria used are low clouds, low view angle, and the highest NDVI/EVI value. Descriptions taken from the Goole Earth Engine Data Catalog. Facebook API data Speedtest Data Data Gathering Classes We divide our data gathering methods into two superclasses: one called OpenData, which is a parent class to each of our open-source data gathering classes; and one called Country, which is a parent class to our school and survey data classes. OpenData: classDiagram OpenData < |-- PopulationData OpenData < |-- SpeedtestData OpenData < |-- FacebookData OpenData < |-- OpenCellData class OpenData{ +set_country_geo() } class PopulationData{ +set_pop_data() } class SpeedtestData{ +type +year +quarter +set_speedtest_data() +tile_prep() } class FacebookData{ +locations +access_token +ad_account_id +call_limit +radius +set_fb_data() } class OpenCellData{ +access_token +set_cell_data() +call_prep() } Country: classDiagram Country < |-- School Country < |-- Survey Survey < |-- BRA_Survey Survey < |-- THA_Survey class Country{ +set_country_geometry() } class School{ +buffer +set_school_data() +school_prep() } class BRA_Survey{ +get_area_links() +set_survey_data() } class THA_Survey{ +set_area_data() +set_survey_data() } Data Dictionary Show a table of each of the predictors and what their definitions are: Variable Name Description Data Source avg_d_kbp3 Average Download Speed Speedtest Data avg_u_kbps Average Upload Speed Speedtest Data estimate_dau Facebook Daily Active Users estimate Facebook API estimate_mau Facebook Monthly Active Users estimate Facebook API population Population within a 1 km buffer zone, estimated with ?? Population Data pop_norm Population normalized Population Data mean_ghm Mean Global Human Modification value Global Human Modification Index mean_avg_rad Mean value from the Average Radiance band VIIRS Nighttime DNB mean_cf_cvg Mean value from the cloud free coverage band VIIRS Nighttime DNB slope_year_avg_rad The yearly rate of change between 2019 and 2014 of Average Radiance VIIRS Nighttime DNB change_year_avg_rad The change between the average values of 2019 and 2014 of Average Radiance VIIRS Nighttime DNB slope_year_cf_cvg The yearly rate of change between 2019 and 2014 from the Cloud Free Coverage Band VIIRS Nighttime DNB change_year_cf_cvg The change between the average values of 2019 and 2014 from the Cloud Free Coverage Band VIIRS Nighttime DNB slope_month_avg_rad The monthly rate of change between 2019 and 2014 of the Average Radiance Band VIIRS Nighttime DNB change_month_avg_rad The change between the average of Dec 2019 and Jan 2014 of the Average Radiance Band VIIRS Nighttime DNB slope_month_cf_cvg The monthly rate of change between 2019 and 2014 from the Cloud Free Coverage Band VIIRS Nighttime DNB change_month_cf_cvg The rate of change between the average of Dec 2019 and Jan 2014 from the Cloud Free Coverage Band VIIRS Nighttime DNB mean_NDVI The average value of the Vegetation Index MODIS Dataset slope_year_NDVI The yearly rate of change between 2019 and 2014 of the Vegetation Index MODIS Dataset change_year_NDVI The change between 2019 and 2014 of the Vegetation Index MODIS Dataset slope_month_NDVI The monthly rate of change between 2019 and 2014 of the Vegetation Index MODIS Dataset change_month_NDVI The change between the average of May 2019 and May 2014 of the Vegetation Index MODIS Dataset","title":"Data Gathering"},{"location":"datagat/#data-gathering","text":"Utku did a lot of work on this. Yay Utku!!","title":"Data Gathering"},{"location":"datagat/#internal-data","text":"Surveys from ITU for Brazil and Thailand The target variable for our modeling was the proportion of a population around a particular school that was connected to the internet. It therefore ranged from 0-1, with 0 being zero percent connected and 100 being 100% connected to the internet. We chose to measure this on a school level as one of our objectives, through working with UNICEF, was to detect schools that could be connected to the internet and further serve the community they are located. Within the Brazil Survey data, we received information on household internet connectivity on an enumeration area level. This presented a slight challenge as the level of granularity of the school data was slightly different from the enumeration data or census tract. Thus, we matched the school points to the enumeration area data. We could not use all the school points as we only had enumeration areas for a specific amount of tracts in Brazil. Thus we had to subset our school points data to around 11,000 points. Once we connected the schools to the enumeration areas we were able to build our training data set. School Points from UNICEF for Brazil We got the school points in lat, long format from UNICEF for Brazil. Unfortunately, we were not able to obtain the school points for Thailand. We thus turned to OpenStreetMap to obtain school points for Thailand. We obtained many school points but filtered them to the schools that we were positive were schools as some were tagged as dance schools or even ATM's. Our school points script is thus specific for obtaining the OSM points. Should we say something about the licensing?","title":"Internal Data"},{"location":"datagat/#externalopen-source-data","text":"We now have to gather all the open data that we've used: Open Cell ID School Population Points using OSM Satellite data To see the full code for gathering this data, click here. To gather the satellite data, we used Google Earth Engine for Python API. We gathered three different types of data: Global Human Modification Index, Nighttime Data, Normalized Difference Vegetation Index. Our hope with gathering this data is that it would provide an accurate proxy for households and schools with internet connection. If we knew a school was located in a place with a high average radiance, it might also mean there was high internet connectivity. The beauty of satellite data is that its continous for the entire globe. We initially struggled with learning how to crop the data for all the school points we wanted. Eventually, we set a 5 km buffer zone around each school point in both Brazil and Thailand and obtained specific satellite information that was input as a number into the training dataset. Below please find more information on each of the datasets we used. Global Human Modification Index (String for Image Collection ID is: 'CSP/HM/GlobalHumanModification'): The global Human Modification dataset (gHM) provides a cumulative measure of human modification of terrestrial lands globally at 1 square-kilometer resolution. The gHM values range from 0.0-1.0 and are calculated by estimating the proportion of a given location (pixel) that is modified, the estimated intensity of modification associated with a given type of human modification or \"stressor\". 5 major anthropogenic stressors circa 2016 were mapped using 13 individual datasets: human settlement (population density, built-up areas) agriculture (cropland, livestock) transportation (major, minor, and two-track roads; railroads) mining and energy production electrical infrastructure (power lines, nighttime lights) NOAA Monthly Nighttime images using the VIIRS Satellite (String for Image Collection ID is: \"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\") Monthly average radiance composite images using nighttime data from the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB). As these data are composited monthly, there are many areas of the globe where it is impossible to get good quality data coverage for that month. This can be due to cloud cover, especially in the tropical regions, or due to solar illumination, as happens toward the poles in their respective summer months. Therefore it is recommended that users of these data utilize the 'cf_cvg' band and not assume a value of zero in the average radiance image means that no lights were observed. Normalized Difference Vegetation Index Band from the MODIS dataset (String for Image Collection ID is: 'MODIS/006/MOD13A2'): Normalized Difference Vegetation Index or NDVI measures the vegetation or greenness present on the Earth's surface The algorithm for this product chooses the best available pixel value from all the acquisitions from the 16-day period. The criteria used are low clouds, low view angle, and the highest NDVI/EVI value. Descriptions taken from the Goole Earth Engine Data Catalog. Facebook API data Speedtest Data","title":"External/Open Source Data"},{"location":"datagat/#data-gathering-classes","text":"We divide our data gathering methods into two superclasses: one called OpenData, which is a parent class to each of our open-source data gathering classes; and one called Country, which is a parent class to our school and survey data classes.","title":"Data Gathering Classes"},{"location":"datagat/#opendata","text":"classDiagram OpenData < |-- PopulationData OpenData < |-- SpeedtestData OpenData < |-- FacebookData OpenData < |-- OpenCellData class OpenData{ +set_country_geo() } class PopulationData{ +set_pop_data() } class SpeedtestData{ +type +year +quarter +set_speedtest_data() +tile_prep() } class FacebookData{ +locations +access_token +ad_account_id +call_limit +radius +set_fb_data() } class OpenCellData{ +access_token +set_cell_data() +call_prep() }","title":"OpenData:"},{"location":"datagat/#country","text":"classDiagram Country < |-- School Country < |-- Survey Survey < |-- BRA_Survey Survey < |-- THA_Survey class Country{ +set_country_geometry() } class School{ +buffer +set_school_data() +school_prep() } class BRA_Survey{ +get_area_links() +set_survey_data() } class THA_Survey{ +set_area_data() +set_survey_data() }","title":"Country:"},{"location":"datagat/#data-dictionary","text":"Show a table of each of the predictors and what their definitions are: Variable Name Description Data Source avg_d_kbp3 Average Download Speed Speedtest Data avg_u_kbps Average Upload Speed Speedtest Data estimate_dau Facebook Daily Active Users estimate Facebook API estimate_mau Facebook Monthly Active Users estimate Facebook API population Population within a 1 km buffer zone, estimated with ?? Population Data pop_norm Population normalized Population Data mean_ghm Mean Global Human Modification value Global Human Modification Index mean_avg_rad Mean value from the Average Radiance band VIIRS Nighttime DNB mean_cf_cvg Mean value from the cloud free coverage band VIIRS Nighttime DNB slope_year_avg_rad The yearly rate of change between 2019 and 2014 of Average Radiance VIIRS Nighttime DNB change_year_avg_rad The change between the average values of 2019 and 2014 of Average Radiance VIIRS Nighttime DNB slope_year_cf_cvg The yearly rate of change between 2019 and 2014 from the Cloud Free Coverage Band VIIRS Nighttime DNB change_year_cf_cvg The change between the average values of 2019 and 2014 from the Cloud Free Coverage Band VIIRS Nighttime DNB slope_month_avg_rad The monthly rate of change between 2019 and 2014 of the Average Radiance Band VIIRS Nighttime DNB change_month_avg_rad The change between the average of Dec 2019 and Jan 2014 of the Average Radiance Band VIIRS Nighttime DNB slope_month_cf_cvg The monthly rate of change between 2019 and 2014 from the Cloud Free Coverage Band VIIRS Nighttime DNB change_month_cf_cvg The rate of change between the average of Dec 2019 and Jan 2014 from the Cloud Free Coverage Band VIIRS Nighttime DNB mean_NDVI The average value of the Vegetation Index MODIS Dataset slope_year_NDVI The yearly rate of change between 2019 and 2014 of the Vegetation Index MODIS Dataset change_year_NDVI The change between 2019 and 2014 of the Vegetation Index MODIS Dataset slope_month_NDVI The monthly rate of change between 2019 and 2014 of the Vegetation Index MODIS Dataset change_month_NDVI The change between the average of May 2019 and May 2014 of the Vegetation Index MODIS Dataset","title":"Data Dictionary"},{"location":"eda/","text":"Exploratory Data Analysis Satellite Data The first thing we wanted to explore in our Exploratory Data Analysis was some maps of what our countries looked like and how our predictors might map onto our countries. We used Google Earth Engine to create some maps of nighttime imagery, the global human modification index and the vegetation index. For nighttime and vegetation index, we also wanted to show the change in time as we were using the rate of change as a predictor as well. Below you will find some static images of the maps we created. If you click on them, you can also find an interactive version. Click here to see the Jupyter notebook with code included for replicating the maps below and here for the html version . Satellite Images on a National Level for both Brazil and Thailand: Average Radiance Band Here we see that the Average light comes from the big cities in the south for both countries. This predictor later plays a big role in determining internet connectivity. Click on this map to see a comparison between school points and the entire country average radiance in 2014 and in 2019. Cloud Free Band This is a second band within the VIIRS Satellite nighttime images. It measures light without clouds or solar illumination. In some ways, specifically in tropical rainforests which both Brazil and Thailand have, it is a better measure of light emittance than the average radiance band. We use both as predictors in our model. Additionally, you see in the maps that the light emittance looks vastly different. Click on this map to see a comparison between school points and the entire country cloud free coverage in 2014 and in 2019. Global Human Modification Map In this map, we see the level of Global Human Modification in the last few years within both Brazil and Thailand. For more information on how this dataset was compiled, please see the Data Gathering page. Click on this Brazil Map to see the country level data. Normalized Difference Vegetation Index Here we see the difference in vegetation between Brazil and Thailand. Click here to see the map for Brazil, toggle between the layers to see the entire country and just the school point areas. Here we also see GIFs that show the time series change of vegetation from 2000 to 2021. Speedtest data Open Cell ID data Facebook Data Training Set EDA We also did some Exploratory Data Analysis once our training dataset was created. Click Here for the full notebook of explanatory visualizations. Click here for the Jupyter Notebook .ipynb file.","title":"Exploratory Data Analysis"},{"location":"eda/#exploratory-data-analysis","text":"","title":"Exploratory Data Analysis"},{"location":"eda/#satellite-data","text":"The first thing we wanted to explore in our Exploratory Data Analysis was some maps of what our countries looked like and how our predictors might map onto our countries. We used Google Earth Engine to create some maps of nighttime imagery, the global human modification index and the vegetation index. For nighttime and vegetation index, we also wanted to show the change in time as we were using the rate of change as a predictor as well. Below you will find some static images of the maps we created. If you click on them, you can also find an interactive version. Click here to see the Jupyter notebook with code included for replicating the maps below and here for the html version . Satellite Images on a National Level for both Brazil and Thailand: Average Radiance Band Here we see that the Average light comes from the big cities in the south for both countries. This predictor later plays a big role in determining internet connectivity. Click on this map to see a comparison between school points and the entire country average radiance in 2014 and in 2019. Cloud Free Band This is a second band within the VIIRS Satellite nighttime images. It measures light without clouds or solar illumination. In some ways, specifically in tropical rainforests which both Brazil and Thailand have, it is a better measure of light emittance than the average radiance band. We use both as predictors in our model. Additionally, you see in the maps that the light emittance looks vastly different. Click on this map to see a comparison between school points and the entire country cloud free coverage in 2014 and in 2019. Global Human Modification Map In this map, we see the level of Global Human Modification in the last few years within both Brazil and Thailand. For more information on how this dataset was compiled, please see the Data Gathering page. Click on this Brazil Map to see the country level data. Normalized Difference Vegetation Index Here we see the difference in vegetation between Brazil and Thailand. Click here to see the map for Brazil, toggle between the layers to see the entire country and just the school point areas. Here we also see GIFs that show the time series change of vegetation from 2000 to 2021.","title":"Satellite Data"},{"location":"eda/#speedtest-data","text":"","title":"Speedtest data"},{"location":"eda/#open-cell-id-data","text":"","title":"Open Cell ID data"},{"location":"eda/#facebook-data","text":"","title":"Facebook Data"},{"location":"eda/#training-set-eda","text":"We also did some Exploratory Data Analysis once our training dataset was created. Click Here for the full notebook of explanatory visualizations. Click here for the Jupyter Notebook .ipynb file.","title":"Training Set EDA"},{"location":"fe/","text":"mermaid.initialize({startOnLoad:true}); mermaidAPI.initialize({ securityLevel: 'loose' }); Feature Engineering Having retrieved data of many different types, at different geospatial resolutions, from an array of different sources, it was necessary to develop a robust and comprehensive feature engineering pipeline, which produces clean datasets, ready for model training or application. Data Cleaning Numerical Variables - Impute missing values as variable median. Categorical Variables - Fill missing values with 'missing' label; perform one-hot encoding. Target Variable Our target variable is ground-truth survey data on local internet connectivity. For the Brazilian and Thai surveys, fowarded to us by ITU, these target variables correspond to the following labels: Brazil - A4A Thailand - H107 Joining Locations In the following description, we use the word 'feature' to mean predictor and, in some cases, ground truth survey variable. The map_feature method within the FeatureEngineering class is used to perform a spatial join between school locations and feature values. In essence, we are finding the correct value of each feature at each given school location. To do so, we first ensure that the dataframe corresponding to each predictor or survey dataset is loaded as a geodataframe, with an appropriately defined 'geometry' column. If the feature's geometry is a polygon, or multipolygon, rather than a point, we take the centroid as the location with which to match. If, instead, the feature's geometry is defined by latitude and longitude columns, rather than a single geometry column, this will be handled appropriately, so long as these column names are exactly 'latitude' and 'longitude', or 'lat' and 'lon'. For the unexpected instance in which schools have already been matched to feature values, we look for a 'source_school_id' column and merge the school data to the feature data according to these school ids. This is for the sake of code robustness, in case features that are already mapped to schools are mistakenly passed to the map_feature method. The build_tree method is then called to implement Scikit-learn's KDTree package and thus build a kd tree of the previously defined centroids. The kd tree is a tree in k-dimensional space; for us, this defines the spatial relationships between locations. This tree is then queried with the school locations to get the nearest neighbours, with the query returning dist (geographic distance) and ind (index associated with this location). The rows in the school_data dataframe are then assigned the correct values for each new column. For any variable named 'range', such as the mobile cell tower range variable from the OpenCellID dataset, values are converted to a 0 or 1, corresponding to range < dist and range >= dist respectively. This last part converts any 'range' to a binary variable, representing out-of-range, or in-range. If Dataset Is Sparsely Scattered across Country: It should be noted that the map_feature method should only be used for features that are not sparsely distributed. For example, this method is not used for the Brazil survey data, which is only available for a selection of enumeration areas, which often have significant geographic regions between them. For other features, such as the Brazil survey data, which have values only in sparsely distributed locations, we employ the map_enumeration method, which joins school locations to areas via intersections between the enumeration area polygons and 1km radius school buffer zones. We then check for instances in which a school might have been joined to multiple enumeration areas and select only the nearest enumeration area for such cases. High Level Feature Engineering Pipeline graph TD A[Get School Data] --> B{Is Survey Available?}; B --> |Yes| C[Get Survey Data]; B --> |No| D[Load Predictor Dataset]; C --> E D --> E[Initialise New Columns]; E --> F[Clean New Data]; F --> G[Match New Data to Schools]; G --> H{All Features Added?}; H --> |Yes| I[Save Dataset] H --> |No| D;","title":"Feature Engineering"},{"location":"fe/#feature-engineering","text":"Having retrieved data of many different types, at different geospatial resolutions, from an array of different sources, it was necessary to develop a robust and comprehensive feature engineering pipeline, which produces clean datasets, ready for model training or application.","title":"Feature Engineering"},{"location":"fe/#data-cleaning","text":"Numerical Variables - Impute missing values as variable median. Categorical Variables - Fill missing values with 'missing' label; perform one-hot encoding.","title":"Data Cleaning"},{"location":"fe/#target-variable","text":"Our target variable is ground-truth survey data on local internet connectivity. For the Brazilian and Thai surveys, fowarded to us by ITU, these target variables correspond to the following labels: Brazil - A4A Thailand - H107","title":"Target Variable"},{"location":"fe/#joining-locations","text":"In the following description, we use the word 'feature' to mean predictor and, in some cases, ground truth survey variable. The map_feature method within the FeatureEngineering class is used to perform a spatial join between school locations and feature values. In essence, we are finding the correct value of each feature at each given school location. To do so, we first ensure that the dataframe corresponding to each predictor or survey dataset is loaded as a geodataframe, with an appropriately defined 'geometry' column. If the feature's geometry is a polygon, or multipolygon, rather than a point, we take the centroid as the location with which to match. If, instead, the feature's geometry is defined by latitude and longitude columns, rather than a single geometry column, this will be handled appropriately, so long as these column names are exactly 'latitude' and 'longitude', or 'lat' and 'lon'. For the unexpected instance in which schools have already been matched to feature values, we look for a 'source_school_id' column and merge the school data to the feature data according to these school ids. This is for the sake of code robustness, in case features that are already mapped to schools are mistakenly passed to the map_feature method. The build_tree method is then called to implement Scikit-learn's KDTree package and thus build a kd tree of the previously defined centroids. The kd tree is a tree in k-dimensional space; for us, this defines the spatial relationships between locations. This tree is then queried with the school locations to get the nearest neighbours, with the query returning dist (geographic distance) and ind (index associated with this location). The rows in the school_data dataframe are then assigned the correct values for each new column. For any variable named 'range', such as the mobile cell tower range variable from the OpenCellID dataset, values are converted to a 0 or 1, corresponding to range < dist and range >= dist respectively. This last part converts any 'range' to a binary variable, representing out-of-range, or in-range.","title":"Joining Locations"},{"location":"fe/#if-dataset-is-sparsely-scattered-across-country","text":"It should be noted that the map_feature method should only be used for features that are not sparsely distributed. For example, this method is not used for the Brazil survey data, which is only available for a selection of enumeration areas, which often have significant geographic regions between them. For other features, such as the Brazil survey data, which have values only in sparsely distributed locations, we employ the map_enumeration method, which joins school locations to areas via intersections between the enumeration area polygons and 1km radius school buffer zones. We then check for instances in which a school might have been joined to multiple enumeration areas and select only the nearest enumeration area for such cases.","title":"If Dataset Is Sparsely Scattered across Country:"},{"location":"fe/#high-level-feature-engineering-pipeline","text":"graph TD A[Get School Data] --> B{Is Survey Available?}; B --> |Yes| C[Get Survey Data]; B --> |No| D[Load Predictor Dataset]; C --> E D --> E[Initialise New Columns]; E --> F[Clean New Data]; F --> G[Match New Data to Schools]; G --> H{All Features Added?}; H --> |Yes| I[Save Dataset] H --> |No| D;","title":"High Level Feature Engineering Pipeline"},{"location":"folder_structure/","text":"Folder Structure files/ src/ scripts/ configs.py main.py data_pipeline.py country.py opendata.py school.py survey.py opendata_facebook.py opendata_scrap.py data/ geodata/ school_loc/ enumeration_area/ fb/ opencellid/ satellite/ speedtest/ survey/ training_sets/ worldpop/","title":"Folder Structure"},{"location":"folder_structure/#folder-structure","text":"files/ src/ scripts/ configs.py main.py data_pipeline.py country.py opendata.py school.py survey.py opendata_facebook.py opendata_scrap.py data/ geodata/ school_loc/ enumeration_area/ fb/ opencellid/ satellite/ speedtest/ survey/ training_sets/ worldpop/","title":"Folder Structure"},{"location":"intro/","text":"Introduction Motivation To this date, just six out of ten people on the globe have access to the internet. In today's fast paced, digital world being offline excludes individuals from large parts of social life. The capabilities of the internet have largely surmounted mere communication, as it grants access to global knowledge, political participation and new economic areas. The internet has been shown to be a crucial background to human and economic development in the past. Therefore Giga Initiative, originated by the International Telecommunication Union (ITU) and UNICEF, has set its goal to connect every school to the internet until 2030. Giving students the opportunity to access and explore the internet prevents transferring inequalities to the future, as basic online knowledge and skills will be essential to participate in the globalized world. In addition to that, schools often serve as community hubs for the entire population around it and are capable of granting them access to the online world. Using the internet necessarily requires an online device and electricity, however individuals might not have the resources for this investment. Being able to use a school's internet devices can yield basic connectivity for a large number of people. Nevertheless, connecting schools in random order (e.g. from A to Z) does not allocate resources where they are most needed. Connecting schools that are most visible or apply for a connection could potentially even aggravate disparities within a country, since offline communities are typically hard-to-target. Therefore, our project aims to provide a resonable priorization mechanism, to determine which school's connection would positively affect the largest number of individuals. Use Case We are trying to create multiple objectives. First, we are aiming to determine the share of households/individuals with internet connectivity around a school. Internet connectivity in this instance is defined as any ability to get online. This means both broadband and mobile internet connection. Additionally, it means that individuals must have devices to be able to connect to the internet. In a next step, we are taking the absolute population number around the school into account and are then able to estimate the offline population around a school. A prioritizing list of all schools featured can then be provided, that reasonably suggests where resource allocation creates the largest benefit. Possibly even the feasability of connection could be regarded in this process, as previous school location databases have had information on computer availability in a school. Schools that already have electricity and computer access should be less complex to be provided with internet. Our second objective, for ITU, is to aggregate our understanding of internet connectivity on a school level up to a country level. While this might already exist for many countries, it will be helpful in countries where there are currently no surveys or established statistics at hand. Furthermore, an elaborate prediction has the potential to even be more accurate or more complete than a national survey. Our model will establish a baseline metric for a country and build greater understanding of countries that have lower or high internet connectivity. The geographical nature of analysis also makes it possible to detect regional and local differences. Ultimately, we are contributing to the field of offline population research. We gain fruitful insights on which features and models are most efficient in predicting internet connectivtiy, which can be used by researchers and organizations. We document our processes and analyses and eventually interpret and discuss our findings. The collection of scripts and documentation can be cloned via the GitHub repository (link).","title":"Introduction"},{"location":"intro/#introduction","text":"","title":"Introduction"},{"location":"intro/#motivation","text":"To this date, just six out of ten people on the globe have access to the internet. In today's fast paced, digital world being offline excludes individuals from large parts of social life. The capabilities of the internet have largely surmounted mere communication, as it grants access to global knowledge, political participation and new economic areas. The internet has been shown to be a crucial background to human and economic development in the past. Therefore Giga Initiative, originated by the International Telecommunication Union (ITU) and UNICEF, has set its goal to connect every school to the internet until 2030. Giving students the opportunity to access and explore the internet prevents transferring inequalities to the future, as basic online knowledge and skills will be essential to participate in the globalized world. In addition to that, schools often serve as community hubs for the entire population around it and are capable of granting them access to the online world. Using the internet necessarily requires an online device and electricity, however individuals might not have the resources for this investment. Being able to use a school's internet devices can yield basic connectivity for a large number of people. Nevertheless, connecting schools in random order (e.g. from A to Z) does not allocate resources where they are most needed. Connecting schools that are most visible or apply for a connection could potentially even aggravate disparities within a country, since offline communities are typically hard-to-target. Therefore, our project aims to provide a resonable priorization mechanism, to determine which school's connection would positively affect the largest number of individuals.","title":"Motivation"},{"location":"intro/#use-case","text":"We are trying to create multiple objectives. First, we are aiming to determine the share of households/individuals with internet connectivity around a school. Internet connectivity in this instance is defined as any ability to get online. This means both broadband and mobile internet connection. Additionally, it means that individuals must have devices to be able to connect to the internet. In a next step, we are taking the absolute population number around the school into account and are then able to estimate the offline population around a school. A prioritizing list of all schools featured can then be provided, that reasonably suggests where resource allocation creates the largest benefit. Possibly even the feasability of connection could be regarded in this process, as previous school location databases have had information on computer availability in a school. Schools that already have electricity and computer access should be less complex to be provided with internet. Our second objective, for ITU, is to aggregate our understanding of internet connectivity on a school level up to a country level. While this might already exist for many countries, it will be helpful in countries where there are currently no surveys or established statistics at hand. Furthermore, an elaborate prediction has the potential to even be more accurate or more complete than a national survey. Our model will establish a baseline metric for a country and build greater understanding of countries that have lower or high internet connectivity. The geographical nature of analysis also makes it possible to detect regional and local differences. Ultimately, we are contributing to the field of offline population research. We gain fruitful insights on which features and models are most efficient in predicting internet connectivtiy, which can be used by researchers and organizations. We document our processes and analyses and eventually interpret and discuss our findings. The collection of scripts and documentation can be cloned via the GitHub repository (link).","title":"Use Case"},{"location":"modapp/","text":"Model Application Thailand Our next big step was applying the best model to Thailand data. We were curious to apply the model as we were not sure that the same assumptions that are true for Brazil would hold true for Thailand. While the satellite data and vegetation may look the same, the national level economic and political indicators were not accounted for in the model. This is because, due to the project scope and capacity, we did not train multiple different national models. Had we had more time and data, perhaps this would have been an alternative route and we could have included some of this information. Instead, we trained a model exclusively on Brazil. For more discussion on future multi-national models, please see the conclusion. Therefore, the limitations for our model rooted in basic assumptions that local areas can be comparable. Our second set of limitations was in the nature of the Thailand data. We wanted to predict and evaluate the Thai schools in the same manner that we did for the Brazil schools. However, the survey data that served as ground truth for Brazil was on an enumeration area level while the survey data for Thailand was on a province area level (of which there are 77 in Thailand). These area units are not comparable and therefore made the evaluation for Thailand more complicated. Below you can see our predictions on a school level which look generally good, though there is no ground truth by which to evaluate. We then scale these school predictions up to a province level. When we get to the province level evaluation, our predictions look much worse. This perhaps can reflect upon our model and its questionable performance, but it also reflects on the raw survey data itself as we are skeptical of the amount of provinces that have 100% internet connectivity to begin with. Steps in our model application to new data. Please click here for a complete predict.py script. Click here for a Jupyter notebook with the XGBoost Predictions and its html equivalent. Using the model_config, we load the Thailand data with the school points and the same predictors used by the original model. Then, we load the model from mlflow where it was pickled as an artifact. Here's some code showing how it was reloaded. Then we examine the predictions on a map: Here are the maps that show the schools' predictions from 0-1 in Thailand. These are all the schools in Thailand, as one can tell it looks reasonable. Here are the schoools just below 50% internet connectivity, predicted by the best Random Forest Model and the best XGBoost Model. There are 97 schools predicted in both, but slightly different pattern of schools. In order to compare our predictions to the ground truth, we aggregated the schools up to a province level as we only have the survey data on that level. This proved challenging for a number of reasons as stated above. Here is what our model prediction look like compared to ground truth, as you can tell they are very different from each other: While our mean province level error is .35, which is not terrible, we can see that the model predictions on a province level diverge greatly from the existing ground truth. Therefore, we are uncertain about the ability for our Brazil model to accurately predict schools with low internet connectivity in Thailand. Philippines We also were able to test this out on the Philippines. The Philippines had better data as their surveys were on an enumeration area level. Here are the results from our Philippines predictions.","title":"Model Application"},{"location":"modapp/#model-application","text":"","title":"Model Application"},{"location":"modapp/#thailand","text":"Our next big step was applying the best model to Thailand data. We were curious to apply the model as we were not sure that the same assumptions that are true for Brazil would hold true for Thailand. While the satellite data and vegetation may look the same, the national level economic and political indicators were not accounted for in the model. This is because, due to the project scope and capacity, we did not train multiple different national models. Had we had more time and data, perhaps this would have been an alternative route and we could have included some of this information. Instead, we trained a model exclusively on Brazil. For more discussion on future multi-national models, please see the conclusion. Therefore, the limitations for our model rooted in basic assumptions that local areas can be comparable. Our second set of limitations was in the nature of the Thailand data. We wanted to predict and evaluate the Thai schools in the same manner that we did for the Brazil schools. However, the survey data that served as ground truth for Brazil was on an enumeration area level while the survey data for Thailand was on a province area level (of which there are 77 in Thailand). These area units are not comparable and therefore made the evaluation for Thailand more complicated. Below you can see our predictions on a school level which look generally good, though there is no ground truth by which to evaluate. We then scale these school predictions up to a province level. When we get to the province level evaluation, our predictions look much worse. This perhaps can reflect upon our model and its questionable performance, but it also reflects on the raw survey data itself as we are skeptical of the amount of provinces that have 100% internet connectivity to begin with. Steps in our model application to new data. Please click here for a complete predict.py script. Click here for a Jupyter notebook with the XGBoost Predictions and its html equivalent. Using the model_config, we load the Thailand data with the school points and the same predictors used by the original model. Then, we load the model from mlflow where it was pickled as an artifact. Here's some code showing how it was reloaded. Then we examine the predictions on a map: Here are the maps that show the schools' predictions from 0-1 in Thailand. These are all the schools in Thailand, as one can tell it looks reasonable. Here are the schoools just below 50% internet connectivity, predicted by the best Random Forest Model and the best XGBoost Model. There are 97 schools predicted in both, but slightly different pattern of schools. In order to compare our predictions to the ground truth, we aggregated the schools up to a province level as we only have the survey data on that level. This proved challenging for a number of reasons as stated above. Here is what our model prediction look like compared to ground truth, as you can tell they are very different from each other: While our mean province level error is .35, which is not terrible, we can see that the model predictions on a province level diverge greatly from the existing ground truth. Therefore, we are uncertain about the ability for our Brazil model to accurately predict schools with low internet connectivity in Thailand.","title":"Thailand"},{"location":"modapp/#philippines","text":"We also were able to test this out on the Philippines. The Philippines had better data as their surveys were on an enumeration area level. Here are the results from our Philippines predictions.","title":"Philippines"},{"location":"model/","text":"Modeling Section: The model we need to train is a regression model as we are attempting to predict a number between 0 and 1 of internet connectivity. A result or prediction of 0 means that of the households surveyed (about 11), no households in the enumeration area stated that they had access to internet. A result or prediction of 1 means that every household surveyed in the enumeration area had access to internet. Most responses fell on a scale between 0 and 1, indicating that some but not all families had internet access. Later on, we attempted to turn this into a classification problem to check our work but it did not provide any higher accuracy. Training Set EDA We also did some Exploratory Data Analysis once our training dataset was created. Click Here for the full notebook of explanatory visualizations. Click here for the Jupyter Notebook .ipynb file. Mlflow Set-up (Optional) In order to track our models, we set up autologging in mlflow. Mlflow is an exciting and experimental way of logging models. We set up our model training so that our python script for each model would create a new experiment for each run, it would log each of our model parameters when we did hyperparameter tuning and then log the best parameter at the top. In this way we were able to compare the various parameters logged in each run to determine how to change the grid space of the hyperparameters. We also were then able to compare models to each other. Within mlflow, we also logged the predictors for each run and the requirements for packages and dependencies to run. Each run also logs the best model as an artifact, so one can easily take the model and apply it to new data. We are including both the best model logged, as well as each run, here in order to make this as reproducible as possible. Below you can see a screenshot of a mlflow which logs our best runs, with our best hyperparameters and using our custom metric for evaluation. On the side, you can also see the list of other experiments we ran with different models. ``` #### mlflow setup #### # save runs mlflow.set_tracking_uri(\"file:///files/mlruns\") mlflow.tracking.get_tracking_uri() #Naming the set_experiment dt = date.today().strftime('%d/%m/%Y') experiment_name = dt + model_config['meta']['experiment_name'] mlflow.set_experiment(experiment_name) mlflow_client = mlflow.tracking.MlflowClient() experiment_id = mlflow_client.get_experiment_by_name(experiment_name).experiment_id ``` Here you can see the simplicity of reload the model artifact later on and applying on new data: Model Configuration Once we have mlflow set up and our model_config.yaml file set up, we can run many different experiments using our .py scripts by changing a few things within our yaml file. Click here to see the full yaml file. Below you can also see how it was set up. We use this to steer our scripts and set our parameters. We set up the input data at the top which is our training data, then label the target and predictor variables as well as the name of the experiment and a brief description in run_name. Under the parameters section, we set parameters like test size (which is crucial), the amount of cross validation folds to do, the number of iterations and the threshold for our custom metric. The threshold tells the model which percent of schools with low internet connectivity to focus on. Then within parameters, there are different sections based on what type of model you might decide to run. Our .yaml file contains parameters for grid search within Random Forest, LightGBM and XGBoost. Model Training We tried out 7 different model classes and ran over 100 experiments each containing 20 or more runs that tried various parameters in order to determine which model had the best accuracy. We experimented with various parameters, as well as different combinations of predictors. Below is the final list of predictors we used and a heat map displaying their collinearity. As you can see, there is not high multi-collinearity among our predictors except with the mean global human modification and the mean average radiance. However, we felt both predictors were important and had high feature importance in the model so we decided to keep both in. In this figure, one can see the correlation between predictors and our target variable. Predictors like the global human modification and average radiance have strong correlation. Another way that we improved accuracy was by building a custom metric in order to score both our test set within our cross validation and our final holdout set. The metric calculates errors specifically by taking the prediction below .3 (or another threshold, we also experimented with .5) subtracting that from the ground truth below .3 (or another threshold), taking the absolute value and then returning the average of all those errors. Below please find a code snippet of our custom metric. #Create custom scoring def custom_eval_metric(y_true, y_pred): errors_low = abs(y_pred[y_pred<0.3] - np.asarray(y_true[y_pred<0.3]).flatten()) return np.mean(errors_low) custom_scorer = make_scorer(custom_eval_metric, greater_is_better = False) # define grid search search = GridSearchCV(model, parameters, scoring = custom_scorer, cv = inner_cv , refit=True, verbose = 2) We built this as we understood that it was more important to have better accuracy on schools with lower internet connectivity than higher connectivity. Before insitituting the custom metric, our models were good with predicting the average values, but they did poorly at either end of the spectrum and particularly on the low values. In order to remedy this issue, we first dropped any rows that had an internet connectivity of zero (there were 23 of them). We dropped the zero's because our project partners informed us that they were most likely due to incomplete data and because they skewed our results. Because there were only 23 of them, we felt it did not impact the data class balancing. Secondly, we instituted our custom metric which trained the model to minimize the error score under the .3 level of prediction. The resulting champion out of over 2000 models was XGBoost with an average error of .06 and specifically for under the .3 threshold, had an average error of .05. This means that for schools that are predicted to be below 30%, we can trust the model's predictions, as on average the predictions are only off by 5 percentage points from the ground truth value. Below, you can see the list of all the model classes we tried. Feel free to try out running these models yourselves or reading the code by clicking on the hyper linked script. There is further documentation within each script on how it runs, and how it works with mlflow logging. Linear Regression (see train_Linear_Regression.py) Python script with Mlflow #is this right? Random Forest HTML File Jupyter Notebook Python Script with Mlflow Python script without Mlflow XGBoost HTML File Jupyter Notebook #this is not correct Python Script with Mlflow Python script without Mlflow LightGBM HTML File Jupyter Notebook Python Script with Mlflow SVM Python Script with Mlflow Neural Net Python Script with Mlflow Random Forest Classifier HTML File Jupyter Notebook Model Evaluation and Results Below we see a comparison of all the models. It is clear that Random Forest and XGBoost both have the lowest average error among all the models, therefore they are the winners. Click on this link to see a notebook with the model comparisons. Click here for the HTML version. As you can see from the above graph, our winning model was the XGboost model which produced an error of .06 and a low average error of .05 with the hyper parameters of: eta: .2, max_depth: 9, n_estimators: 550. Click on this link for the notebook with the Random Forest Predictions and click on this link for the notebook with the XGBoost Predictions . Here is a map of our predictions for schools within Brazil. Figure 1 displays the location for all the schools were the ground truth is less than 30% connected to the internet. There are 69 schools in Brazil that have less than 30% internet connectivity. Figure 2 shows the errors in schools where the prediction is less than 30% connected to the internet. While we can see that there are fewer schools that are predicted than that exist, we can trust that our predictions are correct, as the error score is low. This map was made using the Random Forest model which predicts 14 schools. The XGBoost model predicts 29 schools below 30%. Additionally, our predicted schools match up with our ground truth schools. In Figure 3, we see the predictions for all the schools in the test set mapped out. This gives us an understanding of where the higher and lower connected schools are located regionally. It appears that the higher connected schools are on the coast (the yellows and light greens) while the lower connected schools are located more inland. In Figure 4, we see the errors mapped out for the schools in the test set. As we can see most schools have a low error score, which means we can mostly trust the predictions. The schools with higher error scores are also the schools that have less connectivity, which provides even more motivation to use our custom metric as we want to focus on having a lower error score for schools that are less connected. Thus the 14 schools depicted in Figure 2 are the ones that one could prioritize to connect. We also see that our predictions closely mirror the ground truth within the country, as well as an external data source titled Digital 2021: Brazil. Thus we can trust that our model performs well on Brazilian school data. This graph compares predictions to reality. We can see that the points are quite close to the line except within the lower range. Then we see the residuals compared to reality. This is promising as most residuals hug tightly to the line except for the ones at the very low and high end. Lastly, we also see the comparison of distributions between reality and predictions. While the predictions are a bit higher, the overall curves generally follow each other. Model Interpretation As part of our winning models, we wanted to see which predictors had high feature importance within the model. Below, is the graph for both Random Forest and XGBoost feature importances. As one can see, the highest feature importances are the nighttime average radiance predictor and the Facebook monthly active users. Here are the examinations of the shapely values for feature importances. @Jacob or Utku to put in pics","title":"Modeling"},{"location":"model/#modeling-section","text":"The model we need to train is a regression model as we are attempting to predict a number between 0 and 1 of internet connectivity. A result or prediction of 0 means that of the households surveyed (about 11), no households in the enumeration area stated that they had access to internet. A result or prediction of 1 means that every household surveyed in the enumeration area had access to internet. Most responses fell on a scale between 0 and 1, indicating that some but not all families had internet access. Later on, we attempted to turn this into a classification problem to check our work but it did not provide any higher accuracy.","title":"Modeling Section:"},{"location":"model/#training-set-eda","text":"We also did some Exploratory Data Analysis once our training dataset was created. Click Here for the full notebook of explanatory visualizations. Click here for the Jupyter Notebook .ipynb file.","title":"Training Set EDA"},{"location":"model/#mlflow-set-up-optional","text":"In order to track our models, we set up autologging in mlflow. Mlflow is an exciting and experimental way of logging models. We set up our model training so that our python script for each model would create a new experiment for each run, it would log each of our model parameters when we did hyperparameter tuning and then log the best parameter at the top. In this way we were able to compare the various parameters logged in each run to determine how to change the grid space of the hyperparameters. We also were then able to compare models to each other. Within mlflow, we also logged the predictors for each run and the requirements for packages and dependencies to run. Each run also logs the best model as an artifact, so one can easily take the model and apply it to new data. We are including both the best model logged, as well as each run, here in order to make this as reproducible as possible. Below you can see a screenshot of a mlflow which logs our best runs, with our best hyperparameters and using our custom metric for evaluation. On the side, you can also see the list of other experiments we ran with different models. ``` #### mlflow setup #### # save runs mlflow.set_tracking_uri(\"file:///files/mlruns\") mlflow.tracking.get_tracking_uri() #Naming the set_experiment dt = date.today().strftime('%d/%m/%Y') experiment_name = dt + model_config['meta']['experiment_name'] mlflow.set_experiment(experiment_name) mlflow_client = mlflow.tracking.MlflowClient() experiment_id = mlflow_client.get_experiment_by_name(experiment_name).experiment_id ``` Here you can see the simplicity of reload the model artifact later on and applying on new data:","title":"Mlflow Set-up (Optional)"},{"location":"model/#model-configuration","text":"Once we have mlflow set up and our model_config.yaml file set up, we can run many different experiments using our .py scripts by changing a few things within our yaml file. Click here to see the full yaml file. Below you can also see how it was set up. We use this to steer our scripts and set our parameters. We set up the input data at the top which is our training data, then label the target and predictor variables as well as the name of the experiment and a brief description in run_name. Under the parameters section, we set parameters like test size (which is crucial), the amount of cross validation folds to do, the number of iterations and the threshold for our custom metric. The threshold tells the model which percent of schools with low internet connectivity to focus on. Then within parameters, there are different sections based on what type of model you might decide to run. Our .yaml file contains parameters for grid search within Random Forest, LightGBM and XGBoost.","title":"Model Configuration"},{"location":"model/#model-training","text":"We tried out 7 different model classes and ran over 100 experiments each containing 20 or more runs that tried various parameters in order to determine which model had the best accuracy. We experimented with various parameters, as well as different combinations of predictors. Below is the final list of predictors we used and a heat map displaying their collinearity. As you can see, there is not high multi-collinearity among our predictors except with the mean global human modification and the mean average radiance. However, we felt both predictors were important and had high feature importance in the model so we decided to keep both in. In this figure, one can see the correlation between predictors and our target variable. Predictors like the global human modification and average radiance have strong correlation. Another way that we improved accuracy was by building a custom metric in order to score both our test set within our cross validation and our final holdout set. The metric calculates errors specifically by taking the prediction below .3 (or another threshold, we also experimented with .5) subtracting that from the ground truth below .3 (or another threshold), taking the absolute value and then returning the average of all those errors. Below please find a code snippet of our custom metric. #Create custom scoring def custom_eval_metric(y_true, y_pred): errors_low = abs(y_pred[y_pred<0.3] - np.asarray(y_true[y_pred<0.3]).flatten()) return np.mean(errors_low) custom_scorer = make_scorer(custom_eval_metric, greater_is_better = False) # define grid search search = GridSearchCV(model, parameters, scoring = custom_scorer, cv = inner_cv , refit=True, verbose = 2) We built this as we understood that it was more important to have better accuracy on schools with lower internet connectivity than higher connectivity. Before insitituting the custom metric, our models were good with predicting the average values, but they did poorly at either end of the spectrum and particularly on the low values. In order to remedy this issue, we first dropped any rows that had an internet connectivity of zero (there were 23 of them). We dropped the zero's because our project partners informed us that they were most likely due to incomplete data and because they skewed our results. Because there were only 23 of them, we felt it did not impact the data class balancing. Secondly, we instituted our custom metric which trained the model to minimize the error score under the .3 level of prediction. The resulting champion out of over 2000 models was XGBoost with an average error of .06 and specifically for under the .3 threshold, had an average error of .05. This means that for schools that are predicted to be below 30%, we can trust the model's predictions, as on average the predictions are only off by 5 percentage points from the ground truth value. Below, you can see the list of all the model classes we tried. Feel free to try out running these models yourselves or reading the code by clicking on the hyper linked script. There is further documentation within each script on how it runs, and how it works with mlflow logging. Linear Regression (see train_Linear_Regression.py) Python script with Mlflow #is this right? Random Forest HTML File Jupyter Notebook Python Script with Mlflow Python script without Mlflow XGBoost HTML File Jupyter Notebook #this is not correct Python Script with Mlflow Python script without Mlflow LightGBM HTML File Jupyter Notebook Python Script with Mlflow SVM Python Script with Mlflow Neural Net Python Script with Mlflow Random Forest Classifier HTML File Jupyter Notebook","title":"Model Training"},{"location":"model/#model-evaluation-and-results","text":"Below we see a comparison of all the models. It is clear that Random Forest and XGBoost both have the lowest average error among all the models, therefore they are the winners. Click on this link to see a notebook with the model comparisons. Click here for the HTML version. As you can see from the above graph, our winning model was the XGboost model which produced an error of .06 and a low average error of .05 with the hyper parameters of: eta: .2, max_depth: 9, n_estimators: 550. Click on this link for the notebook with the Random Forest Predictions and click on this link for the notebook with the XGBoost Predictions . Here is a map of our predictions for schools within Brazil. Figure 1 displays the location for all the schools were the ground truth is less than 30% connected to the internet. There are 69 schools in Brazil that have less than 30% internet connectivity. Figure 2 shows the errors in schools where the prediction is less than 30% connected to the internet. While we can see that there are fewer schools that are predicted than that exist, we can trust that our predictions are correct, as the error score is low. This map was made using the Random Forest model which predicts 14 schools. The XGBoost model predicts 29 schools below 30%. Additionally, our predicted schools match up with our ground truth schools. In Figure 3, we see the predictions for all the schools in the test set mapped out. This gives us an understanding of where the higher and lower connected schools are located regionally. It appears that the higher connected schools are on the coast (the yellows and light greens) while the lower connected schools are located more inland. In Figure 4, we see the errors mapped out for the schools in the test set. As we can see most schools have a low error score, which means we can mostly trust the predictions. The schools with higher error scores are also the schools that have less connectivity, which provides even more motivation to use our custom metric as we want to focus on having a lower error score for schools that are less connected. Thus the 14 schools depicted in Figure 2 are the ones that one could prioritize to connect. We also see that our predictions closely mirror the ground truth within the country, as well as an external data source titled Digital 2021: Brazil. Thus we can trust that our model performs well on Brazilian school data. This graph compares predictions to reality. We can see that the points are quite close to the line except within the lower range. Then we see the residuals compared to reality. This is promising as most residuals hug tightly to the line except for the ones at the very low and high end. Lastly, we also see the comparison of distributions between reality and predictions. While the predictions are a bit higher, the overall curves generally follow each other.","title":"Model Evaluation and Results"},{"location":"model/#model-interpretation","text":"As part of our winning models, we wanted to see which predictors had high feature importance within the model. Below, is the graph for both Random Forest and XGBoost feature importances. As one can see, the highest feature importances are the nighttime average radiance predictor and the Facebook monthly active users. Here are the examinations of the shapely values for feature importances. @Jacob or Utku to put in pics","title":"Model Interpretation"},{"location":"Images/Images/","text":"","title":"Images"}]}