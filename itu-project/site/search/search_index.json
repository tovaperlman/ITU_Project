{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to our Project ! We are excited you are here. Click on the pages on the right to learn more about our project and find out how to replicate it for yourself.","title":"Home"},{"location":"#welcome-to-our-project","text":"We are excited you are here. Click on the pages on the right to learn more about our project and find out how to replicate it for yourself.","title":"Welcome to our Project !"},{"location":"Meta_data/","text":"Meta Data Information Folder Structure Below is the folder structure for the Github Repository. All of the notebooks and scripts are organized within the below folder structure and data is inputted with relative file paths. Therefore, once you set your own working directory, everything within should run on its own. files/ src/ scripts/ configs.py main.py data_pipeline.py country.py opendata.py school.py survey.py opendata_facebook.py opendata_scrap.py data/ geodata/ school_loc/ enumeration_area/ fb/ opencellid/ satellite/ speedtest/ survey/ training_sets/ worldpop/ notebooks/ Model_Application.ipynb Model_Comparison.ipynb Satellite_Data_EDA.ipynb Training_Data_EDA.ipynb Training_Light_GBM.ipynb Training_Random_Forest.ipynb Training_Random_Forest_Classifier.ipynb Training_XGBoost.ipynb model/ RF_model.sav xgboost_model.pkl conf/ model_config.yaml predict_config.yaml Configurations We use configs.py to store the variable configurations that should be changed according to use-case: WD - Working Directory, e.g. 'C:/Users/itu/DSSGx/' COUNTRY - Country name for current use-case, e.g. 'Thailand' COUNTRY_CODE - Country code for current use-case, e.g. 'tha' AVAILABLE_COUNTRIES - Countries for which survey data with an internet connectivity ground truth variable is available, e.g. list('bra', 'tha') FEATURES - List of predictive features for use-case, e.g. list('speedtest', 'opencell', 'facebook', 'population', 'satellite'). This exemplary list contains each of the five open data sources we have used and they must be sytactically entered as shown. SURVEY_AREAS - Survey dataset geometry join type, 'tiles' if survey will be joined to country administrative region, province, etc., 'enumeration' if survey will be joined to enumeration area geometries SATELLITE_COLLECTIONS - Dictionary that has satellite image collection identifier as a key and image collection band names for multi-band images, e.g. '{'MODIS/006/MOD13A2': ['NDVI']}' SATELITTE_START_YEAR - Start year of satellite imagery collection to be used SATELITTE_END_YEAR - End year of satellite imagery collection to be used SATELITTE_BUFFER - Buffer to define school area for which satellite imagery will be collected, in kilometers SATELITTE_MAX_CALL_SIZE - Google Earth Engine API max feature collection length, by default 5000 points GOOGLE_SERVICES_ACCOUNT - Google Services Account to call Google Earth Engine API GOOGLE_EARTH_ENGINE_API_JSON_KEY - JSON key file name that is located under satellite folder OPENCELLID_ACCESS_TOKEN - OpenCelliD Project API access token as string FACEBOOK_MARKETING_API_ACCESS_TOKEN - Facebook Marketing API access token as string FACEBOOK_AD_ACCOUNT_ID - Facebook Ad account id as string FACEBOOK_CALL_LIMIT - Facebook Ads Management API maximum calls within one hour, by default it is 300 + 40 * (Number of Active Ads) FACEBOOK_RADIUS - Radius to define school area for which Facebook API data will be collected, in kilometers FACEBOOK_SCHOOL_DATA_LEN - # of schools in the dataset to keep facebook data with school length in the name in case schools wanted to be divided into chunks and also approximate Facebook API completion time SPEEDTEST_TILE_TYPE - Service type for Ookla Open Speedtest Dataset can be 'fixed' or 'mobile' representing fixed or mobile network performance aggregates of tiles SPEEDTEST_TILE_YEAR - Speedtest data year, e.g. 2021 SPEEDTEST_TILE_QUARTER - Speedtest data quarter, e.g. 2 POPULATION_DATASET_YEAR - Population counts dataset year Data Dictionaries Data dictionaries should be created for each predictor and survey dataset. Dictionaries for the open-source data and Brazilian, Thai and Philippino survey data already exist and should be located in the data/meta/ folder. An exemplary data dictionary (for speedtest data) is shown below: Number Name Description Type Binary Role Use Comment 1 avg_d_kbps The average download speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 2 avg_u_kbps The average upload speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 3 avg_lat_ms The average latency of all tests performed in the tile, represented in milliseconds num N predictor N 4 tests The number of tests taken in the tile num N predictor N 5 devices The number of unique devices contributing tests in the tile num N predictor N","title":"Meta Data Information"},{"location":"Meta_data/#meta-data-information","text":"","title":"Meta Data Information"},{"location":"Meta_data/#folder-structure","text":"Below is the folder structure for the Github Repository. All of the notebooks and scripts are organized within the below folder structure and data is inputted with relative file paths. Therefore, once you set your own working directory, everything within should run on its own. files/ src/ scripts/ configs.py main.py data_pipeline.py country.py opendata.py school.py survey.py opendata_facebook.py opendata_scrap.py data/ geodata/ school_loc/ enumeration_area/ fb/ opencellid/ satellite/ speedtest/ survey/ training_sets/ worldpop/ notebooks/ Model_Application.ipynb Model_Comparison.ipynb Satellite_Data_EDA.ipynb Training_Data_EDA.ipynb Training_Light_GBM.ipynb Training_Random_Forest.ipynb Training_Random_Forest_Classifier.ipynb Training_XGBoost.ipynb model/ RF_model.sav xgboost_model.pkl conf/ model_config.yaml predict_config.yaml","title":"Folder Structure"},{"location":"Meta_data/#configurations","text":"We use configs.py to store the variable configurations that should be changed according to use-case: WD - Working Directory, e.g. 'C:/Users/itu/DSSGx/' COUNTRY - Country name for current use-case, e.g. 'Thailand' COUNTRY_CODE - Country code for current use-case, e.g. 'tha' AVAILABLE_COUNTRIES - Countries for which survey data with an internet connectivity ground truth variable is available, e.g. list('bra', 'tha') FEATURES - List of predictive features for use-case, e.g. list('speedtest', 'opencell', 'facebook', 'population', 'satellite'). This exemplary list contains each of the five open data sources we have used and they must be sytactically entered as shown. SURVEY_AREAS - Survey dataset geometry join type, 'tiles' if survey will be joined to country administrative region, province, etc., 'enumeration' if survey will be joined to enumeration area geometries SATELLITE_COLLECTIONS - Dictionary that has satellite image collection identifier as a key and image collection band names for multi-band images, e.g. '{'MODIS/006/MOD13A2': ['NDVI']}' SATELITTE_START_YEAR - Start year of satellite imagery collection to be used SATELITTE_END_YEAR - End year of satellite imagery collection to be used SATELITTE_BUFFER - Buffer to define school area for which satellite imagery will be collected, in kilometers SATELITTE_MAX_CALL_SIZE - Google Earth Engine API max feature collection length, by default 5000 points GOOGLE_SERVICES_ACCOUNT - Google Services Account to call Google Earth Engine API GOOGLE_EARTH_ENGINE_API_JSON_KEY - JSON key file name that is located under satellite folder OPENCELLID_ACCESS_TOKEN - OpenCelliD Project API access token as string FACEBOOK_MARKETING_API_ACCESS_TOKEN - Facebook Marketing API access token as string FACEBOOK_AD_ACCOUNT_ID - Facebook Ad account id as string FACEBOOK_CALL_LIMIT - Facebook Ads Management API maximum calls within one hour, by default it is 300 + 40 * (Number of Active Ads) FACEBOOK_RADIUS - Radius to define school area for which Facebook API data will be collected, in kilometers FACEBOOK_SCHOOL_DATA_LEN - # of schools in the dataset to keep facebook data with school length in the name in case schools wanted to be divided into chunks and also approximate Facebook API completion time SPEEDTEST_TILE_TYPE - Service type for Ookla Open Speedtest Dataset can be 'fixed' or 'mobile' representing fixed or mobile network performance aggregates of tiles SPEEDTEST_TILE_YEAR - Speedtest data year, e.g. 2021 SPEEDTEST_TILE_QUARTER - Speedtest data quarter, e.g. 2 POPULATION_DATASET_YEAR - Population counts dataset year","title":"Configurations"},{"location":"Meta_data/#data-dictionaries","text":"Data dictionaries should be created for each predictor and survey dataset. Dictionaries for the open-source data and Brazilian, Thai and Philippino survey data already exist and should be located in the data/meta/ folder. An exemplary data dictionary (for speedtest data) is shown below: Number Name Description Type Binary Role Use Comment 1 avg_d_kbps The average download speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 2 avg_u_kbps The average upload speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 3 avg_lat_ms The average latency of all tests performed in the tile, represented in milliseconds num N predictor N 4 tests The number of tests taken in the tile num N predictor N 5 devices The number of unique devices contributing tests in the tile num N predictor N","title":"Data Dictionaries"},{"location":"about/","text":"This is about our project with ITU. Who are we? Tova Perlman Tova hails from Philadelphia, PA. She graduated in May 2021 with a degree in Urban Spatial Analytics from the University of Pennsylvania and is looking forward to pursuing a career in geospatial data science. The highlight of her summer was meeting new colleagues located internationally and learning how to use geemap API for python. Utku Can Ozturk Jonathan Cook Jacob Beck Project Mentor: Daniel Townsend Technical Mentor: Robert Hager Who is ITU? Who is UNICEF? What is Project Giga?","title":"About the Team"},{"location":"conc/","text":"We have gained a variety of insights that can be used in future research and extension of the analyses. While our technical and methodological learnings have been outlined in the previous sections, the following conclusion will briefly provide an outcome interpretation of the project and then discuss limitations and possible next steps. Outcome Interpretation We developed a tool that is capable of providing multiple outcomes. Firstly, once we've applied a model, we can create a list that prioritizes schools to be connected to the internet within a country. The priorization list created can be sorted either by the absolute number of offline population potentially served or by the relative share of online population. In addition, it is possible to adapt and change the list e.g. by excluding densely populated areas in order to get a list of schools just in lowly populated areas. The latter list prioritizes areas in more rural regions that would benefit from internet connectivity. Moreover, the level of geographic aggregation of the connectivity ratio can be modified up to federal state or full country level. It is currently at the enumeration area level. Our provided scripts in combination with the documentation can now assist institutions and interventions, like the Giga Initiative, to manage resource allocation for connecting schools. This can be done within a country, between multiple countries and potentially on province, region or city level. Aside from the prioritization list, we created a straight-forward tool for data gathering, feature engineering and exploratory data analysis. Using this tool, individuals can create simple map graphics or correlation plots, which might already indicate the presence of clear tendencies and areas likely to have internet without even delving into the modeling. Limitations During our project, we faced a number of limitations, especially with regard to model evaluation. The results make sense within our Brazil model and data, however we have yet to determine how this transfers to the reality of schools and their connectedness. Future extension and application of our models to other countries can help to further evaluate our project outcome. In the special case of Thailand, another problem became obvious: the data provided inherited multiple sources of error and it was not possible to separate these from each other. In this specific case, for instance, the geographic aggregation of the target variable made the model prediction accuracies hard to evaluate. Additionally, it was unclear how much the usage of school points from OSM, instead of school points provided by the local government, had an impact on model performance and error. Because we cannot yet evaluate how OSM school data performs compared to official school location data, its representation should be reviewed once official school points are obtained. If this datasource is supposed to be a cost and resource efficient replacement for UNICEF school data, the accuracy relative to official points is an important next step in evaluating the model. Another limitation of our data sources concerns the Facebook data we extract. There is an element of \"instability\" within the intrepretation of this data as the popularity of Facebook differs over time and between countries. According to demographic indicators, the utilization of it does not remain straight-forward. When we examined the feature importances and impacts, we saw that larger number of Facebook users have generally led to higher predictions of online population. However, if a large metropolitan area, like Sao Paulo, shows a low percentage of Facebook users, this could be due to the fact that another social media platform (such as Instagram) is more popular. As a next step, we would recommend an analysis of dispersion of Facebook users among social strata to prevent a misinterpretation of the data and this specific feature. Another potential source of bias is within our ground truth data itself, which is the survey data provided by the countries' national governemnts. Survey data is typically prone to biasing mechanisms like misreporting or systematic non-response. In the example of misreporting, in some of these surveys, respondents stated that they are not using the internet, but later in the same survey declared themselves internet users. Non-response could be problematic if there is selection bias present within who responds to the survey. Potentially, people who are not connected to the internet are less likely to complete the survey (especially if its a survey conducted over the internet). A potential corroborrating measure here would be comparing the distribution of demographic data within the survey (e.g income, gender) with other open (official) data sources. A major source of concern for us is the selection bias and feedback loop that will take place if the focus of modeling is entirely on countries for which survey data on internet connected populations already exist. One might assume that countries with no microdata on telecommunications are also countries with low connectivity. Further research should place emphasis on taking a systemic approach to creating models and identifying countries with less connected populations, so that they are not missed entirely. Our open source data collection is just the beginning to an approach that will not have to rely on user-informed surveys. Next Steps Additional Methods Multiple additional methods could be applied to our existing models and analyses: Full scoring on Brazil As a reminder, we were only able to serve and evaluate predictions for the small scale of schools that fit within the enumeration areas of survey data we had. Moving forward, all schools outside the featured enumeration areas can now be scored with an estimated level of connectivity using our champion model. This would yield a similar map to the pre-existing Giga Initiative connectivity map. A comparison between both maps would be a sanity check on our predictions and perhaps yield additional insights into schools that need further assistance in internet connection. Statistical robustness checks There are two steps that would help in the quality of our model. One would be to create a geographically weighted regression that would take the school point locations into account. The second would be performing spatial cross validation on the models to ensure that we are accounting for all the spatial information and clustering within the school points themselves. This might also strengthen future predictions. Experiment with featured data The manner in which we used some of the features could be varied. Firstly, one could experiment more with the Facebook data. Perhaps, the Facebook data already suffices as a standalone proxy variable for online population. Hypothetically, this would decrease the need for model estimation and enable a global extension of the project through only using the Facebook API. Furthermore, pulling OSM school locations for Brazil and applying the model to this sample could yield insights on the representativity of OSM data (as a reminder, the school points we used for Brazil came from the government and not from OSM). Lastly, buffer zones around schools are currently constant in diameter, in future iterations of this project, one could vary the diameter not by distance, but rather by a specific variable like population residing within each area. This might ensure more normalization with knowing the actual amount of people each school serves, as one could assume that the catchment areas for schools in rural areas is much larger than in urban areas. Extension to other countries The existing model can be applied to any country that has OSM school location data available. However, model evaluation or model training for other countries requires two more components: microdata (on household, individual or enumeration area level) and the respective shapefiles/geolocation of the enumeration areas. Our analyses have indicated that analyzing larger geographical areas like provinces diminishes model performance and interpretability. An enumeration area is small enough to assume it is largely a homogeneous area. By contrast, there is much more variation in connectivity rates within a federal state. Further model training As we train more models on different countries, there are more options of model combinations and opportunity to create greater generalizability of our model. Given the requirements stated above are met, an individual model can be trained for each country and evaluated separately. Additionally, we could combine multiple individual country models together to create a model with a higher predictive power on a global level, with increased model robustness. Comparing the performances of combined and single-country models might give insights into the impact of country-specific differences (i.e. national economic, or political differences). Furthermore, one could train regional models (e.g. a model for South East Asian countries and a separate one for South American countries). It is our hope that individuals and organizations that are not able to provide enumeration area level microdata (e.g. due to anonymity restrictions) can use our provided scripts and additional content to run their own custom model training. Additional data sources Country-level data The extension of model training to multiple countries provides an opportunity to include national level variables. Possible variables that could be helpful are urbanization rate, GDP, public spendings on telecommunications or other indices of human/infrastructure development on a national level. In doing so, \"country-specific predictors\" are part of the modeling and might assist in accounting for differences in overall connectivity between countries. Additionally, it is important to pay attention to the rate and speed of change around predictors within our model. While two countries might have the same average radiance or GDP today, the speed with which the country is changing and the government is investing in allocating resources towards development is indicative of the overall internet connectivity estimate now and in the future. A great example of national internet statistics and their dependencies on differnet national indicators is provided by the Economist Intelligence Unit's Inclusive Internet Index . Additional content from survey/school data The original models we provided only utilize the necessarily required features of survey and school data, the survey response of if a respondent is connected to the internet and school location points. We chose this approach, and left out all other variables and information present within these data sources, in order to keep our approach as reproducible as possible for other countries, because we knew that the survey questions would vary from country-to-country. For future analysis, we recommend further investigation of connectivity-related variables and questions on telecommunications (e.g reasons for (non-)connectivity), demographic information such as age or gender, and information on household size or income. Similarly, information in school location data, such as pupil count or computer availability, could potentially be used in further analyses, e.g. when trying to estimate the feasability of connection for a specific school. Further data Existing models could supposedly be improved by adding more features to the training data. Possible additions could stem from official data provided by ministries/regulators, platform/network/monitoring services like Google, Facebook or Cisco Analytics, or (coverage) telecommunication data from telecommunication companies and operators. Although, at minimum, a hypothetical logical connection between feature and target variable should always exist. Conclusion Our project goal was to improve approaches to predicting the world's offline population, which we have examined in three case studies: Brazil, Thailand and the Philippines. In doing so we have created tools that can be used by researchers and institutions to investigate the connectivity within a country and for further national and regional comparisons. Hopefully, this documentation has served as guidance for reproduction and offered useful prompts for further analysis and research.","title":"Discussion"},{"location":"conc/#outcome-interpretation","text":"We developed a tool that is capable of providing multiple outcomes. Firstly, once we've applied a model, we can create a list that prioritizes schools to be connected to the internet within a country. The priorization list created can be sorted either by the absolute number of offline population potentially served or by the relative share of online population. In addition, it is possible to adapt and change the list e.g. by excluding densely populated areas in order to get a list of schools just in lowly populated areas. The latter list prioritizes areas in more rural regions that would benefit from internet connectivity. Moreover, the level of geographic aggregation of the connectivity ratio can be modified up to federal state or full country level. It is currently at the enumeration area level. Our provided scripts in combination with the documentation can now assist institutions and interventions, like the Giga Initiative, to manage resource allocation for connecting schools. This can be done within a country, between multiple countries and potentially on province, region or city level. Aside from the prioritization list, we created a straight-forward tool for data gathering, feature engineering and exploratory data analysis. Using this tool, individuals can create simple map graphics or correlation plots, which might already indicate the presence of clear tendencies and areas likely to have internet without even delving into the modeling.","title":"Outcome Interpretation"},{"location":"conc/#limitations","text":"During our project, we faced a number of limitations, especially with regard to model evaluation. The results make sense within our Brazil model and data, however we have yet to determine how this transfers to the reality of schools and their connectedness. Future extension and application of our models to other countries can help to further evaluate our project outcome. In the special case of Thailand, another problem became obvious: the data provided inherited multiple sources of error and it was not possible to separate these from each other. In this specific case, for instance, the geographic aggregation of the target variable made the model prediction accuracies hard to evaluate. Additionally, it was unclear how much the usage of school points from OSM, instead of school points provided by the local government, had an impact on model performance and error. Because we cannot yet evaluate how OSM school data performs compared to official school location data, its representation should be reviewed once official school points are obtained. If this datasource is supposed to be a cost and resource efficient replacement for UNICEF school data, the accuracy relative to official points is an important next step in evaluating the model. Another limitation of our data sources concerns the Facebook data we extract. There is an element of \"instability\" within the intrepretation of this data as the popularity of Facebook differs over time and between countries. According to demographic indicators, the utilization of it does not remain straight-forward. When we examined the feature importances and impacts, we saw that larger number of Facebook users have generally led to higher predictions of online population. However, if a large metropolitan area, like Sao Paulo, shows a low percentage of Facebook users, this could be due to the fact that another social media platform (such as Instagram) is more popular. As a next step, we would recommend an analysis of dispersion of Facebook users among social strata to prevent a misinterpretation of the data and this specific feature. Another potential source of bias is within our ground truth data itself, which is the survey data provided by the countries' national governemnts. Survey data is typically prone to biasing mechanisms like misreporting or systematic non-response. In the example of misreporting, in some of these surveys, respondents stated that they are not using the internet, but later in the same survey declared themselves internet users. Non-response could be problematic if there is selection bias present within who responds to the survey. Potentially, people who are not connected to the internet are less likely to complete the survey (especially if its a survey conducted over the internet). A potential corroborrating measure here would be comparing the distribution of demographic data within the survey (e.g income, gender) with other open (official) data sources. A major source of concern for us is the selection bias and feedback loop that will take place if the focus of modeling is entirely on countries for which survey data on internet connected populations already exist. One might assume that countries with no microdata on telecommunications are also countries with low connectivity. Further research should place emphasis on taking a systemic approach to creating models and identifying countries with less connected populations, so that they are not missed entirely. Our open source data collection is just the beginning to an approach that will not have to rely on user-informed surveys.","title":"Limitations"},{"location":"conc/#next-steps","text":"","title":"Next Steps"},{"location":"conc/#additional-methods","text":"Multiple additional methods could be applied to our existing models and analyses: Full scoring on Brazil As a reminder, we were only able to serve and evaluate predictions for the small scale of schools that fit within the enumeration areas of survey data we had. Moving forward, all schools outside the featured enumeration areas can now be scored with an estimated level of connectivity using our champion model. This would yield a similar map to the pre-existing Giga Initiative connectivity map. A comparison between both maps would be a sanity check on our predictions and perhaps yield additional insights into schools that need further assistance in internet connection. Statistical robustness checks There are two steps that would help in the quality of our model. One would be to create a geographically weighted regression that would take the school point locations into account. The second would be performing spatial cross validation on the models to ensure that we are accounting for all the spatial information and clustering within the school points themselves. This might also strengthen future predictions. Experiment with featured data The manner in which we used some of the features could be varied. Firstly, one could experiment more with the Facebook data. Perhaps, the Facebook data already suffices as a standalone proxy variable for online population. Hypothetically, this would decrease the need for model estimation and enable a global extension of the project through only using the Facebook API. Furthermore, pulling OSM school locations for Brazil and applying the model to this sample could yield insights on the representativity of OSM data (as a reminder, the school points we used for Brazil came from the government and not from OSM). Lastly, buffer zones around schools are currently constant in diameter, in future iterations of this project, one could vary the diameter not by distance, but rather by a specific variable like population residing within each area. This might ensure more normalization with knowing the actual amount of people each school serves, as one could assume that the catchment areas for schools in rural areas is much larger than in urban areas.","title":"Additional Methods"},{"location":"conc/#extension-to-other-countries","text":"The existing model can be applied to any country that has OSM school location data available. However, model evaluation or model training for other countries requires two more components: microdata (on household, individual or enumeration area level) and the respective shapefiles/geolocation of the enumeration areas. Our analyses have indicated that analyzing larger geographical areas like provinces diminishes model performance and interpretability. An enumeration area is small enough to assume it is largely a homogeneous area. By contrast, there is much more variation in connectivity rates within a federal state.","title":"Extension to other countries"},{"location":"conc/#further-model-training","text":"As we train more models on different countries, there are more options of model combinations and opportunity to create greater generalizability of our model. Given the requirements stated above are met, an individual model can be trained for each country and evaluated separately. Additionally, we could combine multiple individual country models together to create a model with a higher predictive power on a global level, with increased model robustness. Comparing the performances of combined and single-country models might give insights into the impact of country-specific differences (i.e. national economic, or political differences). Furthermore, one could train regional models (e.g. a model for South East Asian countries and a separate one for South American countries). It is our hope that individuals and organizations that are not able to provide enumeration area level microdata (e.g. due to anonymity restrictions) can use our provided scripts and additional content to run their own custom model training.","title":"Further model training"},{"location":"conc/#additional-data-sources","text":"Country-level data The extension of model training to multiple countries provides an opportunity to include national level variables. Possible variables that could be helpful are urbanization rate, GDP, public spendings on telecommunications or other indices of human/infrastructure development on a national level. In doing so, \"country-specific predictors\" are part of the modeling and might assist in accounting for differences in overall connectivity between countries. Additionally, it is important to pay attention to the rate and speed of change around predictors within our model. While two countries might have the same average radiance or GDP today, the speed with which the country is changing and the government is investing in allocating resources towards development is indicative of the overall internet connectivity estimate now and in the future. A great example of national internet statistics and their dependencies on differnet national indicators is provided by the Economist Intelligence Unit's Inclusive Internet Index . Additional content from survey/school data The original models we provided only utilize the necessarily required features of survey and school data, the survey response of if a respondent is connected to the internet and school location points. We chose this approach, and left out all other variables and information present within these data sources, in order to keep our approach as reproducible as possible for other countries, because we knew that the survey questions would vary from country-to-country. For future analysis, we recommend further investigation of connectivity-related variables and questions on telecommunications (e.g reasons for (non-)connectivity), demographic information such as age or gender, and information on household size or income. Similarly, information in school location data, such as pupil count or computer availability, could potentially be used in further analyses, e.g. when trying to estimate the feasability of connection for a specific school. Further data Existing models could supposedly be improved by adding more features to the training data. Possible additions could stem from official data provided by ministries/regulators, platform/network/monitoring services like Google, Facebook or Cisco Analytics, or (coverage) telecommunication data from telecommunication companies and operators. Although, at minimum, a hypothetical logical connection between feature and target variable should always exist.","title":"Additional data sources"},{"location":"conc/#conclusion","text":"Our project goal was to improve approaches to predicting the world's offline population, which we have examined in three case studies: Brazil, Thailand and the Philippines. In doing so we have created tools that can be used by researchers and institutions to investigate the connectivity within a country and for further national and regional comparisons. Hopefully, this documentation has served as guidance for reproduction and offered useful prompts for further analysis and research.","title":"Conclusion"},{"location":"configs/","text":"Configurations We use configs.py to store the variable configurations that should be changed according to use-case: WD - Working Directory, e.g. 'C:/Users/itu/DSSGx/' COUNTRY - Country name for current use-case, e.g. 'Thailand' COUNTRY_CODE - Country code for current use-case, e.g. 'tha' AVAILABLE_COUNTRIES - Countries for which survey data with an internet connectivity ground truth variable is available, e.g. list('bra', 'tha') FEATURES - List of predictive features for use-case, e.g. list('speedtest', 'opencell', 'facebook', 'population', 'satellite'). This exemplary list contains each of the five open data sources we have used and they must be sytactically entered as shown. SURVEY_AREAS - Survey dataset geometry join type, 'tiles' if survey will be joined to country administrative region, province, etc., 'enumeration' if survey will be joined to enumeration area geometries SATELLITE_COLLECTIONS - Dictionary that has satellite image collection identifier as a key and image collection band names for multi-band images, e.g. '{'MODIS/006/MOD13A2': ['NDVI']}' SATELITTE_START_YEAR - Start year of satellite imagery collection to be used SATELITTE_END_YEAR - End year of satellite imagery collection to be used SATELITTE_BUFFER - Buffer to define school area for which satellite imagery will be collected, in kilometers SATELITTE_MAX_CALL_SIZE - Google Earth Engine API max feature collection length, by default 5000 points GOOGLE_SERVICES_ACCOUNT - Google Services Account to call Google Earth Engine API GOOGLE_EARTH_ENGINE_API_JSON_KEY - JSON key file name that is located under satellite folder OPENCELLID_ACCESS_TOKEN - OpenCelliD Project API access token as string FACEBOOK_MARKETING_API_ACCESS_TOKEN - Facebook Marketing API access token as string FACEBOOK_AD_ACCOUNT_ID - Facebook Ad account id as string FACEBOOK_CALL_LIMIT - Facebook Ads Management API maximum calls within one hour, by default it is 300 + 40 * (Number of Active Ads) FACEBOOK_RADIUS - Radius to define school area for which Facebook API data will be collected, in kilometers FACEBOOK_SCHOOL_DATA_LEN - # of schools in the dataset to keep facebook data with school length in the name in case schools wanted to be divided into chunks and also approximate Facebook API completion time SPEEDTEST_TILE_TYPE - Service type for Ookla Open Speedtest Dataset can be 'fixed' or 'mobile' representing fixed or mobile network performance aggregates of tiles SPEEDTEST_TILE_YEAR - Speedtest data year, e.g. 2021 SPEEDTEST_TILE_QUARTER - Speedtest data quarter, e.g. 2 POPULATION_DATASET_YEAR - Population counts dataset year","title":"Configurations"},{"location":"configs/#configurations","text":"We use configs.py to store the variable configurations that should be changed according to use-case: WD - Working Directory, e.g. 'C:/Users/itu/DSSGx/' COUNTRY - Country name for current use-case, e.g. 'Thailand' COUNTRY_CODE - Country code for current use-case, e.g. 'tha' AVAILABLE_COUNTRIES - Countries for which survey data with an internet connectivity ground truth variable is available, e.g. list('bra', 'tha') FEATURES - List of predictive features for use-case, e.g. list('speedtest', 'opencell', 'facebook', 'population', 'satellite'). This exemplary list contains each of the five open data sources we have used and they must be sytactically entered as shown. SURVEY_AREAS - Survey dataset geometry join type, 'tiles' if survey will be joined to country administrative region, province, etc., 'enumeration' if survey will be joined to enumeration area geometries SATELLITE_COLLECTIONS - Dictionary that has satellite image collection identifier as a key and image collection band names for multi-band images, e.g. '{'MODIS/006/MOD13A2': ['NDVI']}' SATELITTE_START_YEAR - Start year of satellite imagery collection to be used SATELITTE_END_YEAR - End year of satellite imagery collection to be used SATELITTE_BUFFER - Buffer to define school area for which satellite imagery will be collected, in kilometers SATELITTE_MAX_CALL_SIZE - Google Earth Engine API max feature collection length, by default 5000 points GOOGLE_SERVICES_ACCOUNT - Google Services Account to call Google Earth Engine API GOOGLE_EARTH_ENGINE_API_JSON_KEY - JSON key file name that is located under satellite folder OPENCELLID_ACCESS_TOKEN - OpenCelliD Project API access token as string FACEBOOK_MARKETING_API_ACCESS_TOKEN - Facebook Marketing API access token as string FACEBOOK_AD_ACCOUNT_ID - Facebook Ad account id as string FACEBOOK_CALL_LIMIT - Facebook Ads Management API maximum calls within one hour, by default it is 300 + 40 * (Number of Active Ads) FACEBOOK_RADIUS - Radius to define school area for which Facebook API data will be collected, in kilometers FACEBOOK_SCHOOL_DATA_LEN - # of schools in the dataset to keep facebook data with school length in the name in case schools wanted to be divided into chunks and also approximate Facebook API completion time SPEEDTEST_TILE_TYPE - Service type for Ookla Open Speedtest Dataset can be 'fixed' or 'mobile' representing fixed or mobile network performance aggregates of tiles SPEEDTEST_TILE_YEAR - Speedtest data year, e.g. 2021 SPEEDTEST_TILE_QUARTER - Speedtest data quarter, e.g. 2 POPULATION_DATASET_YEAR - Population counts dataset year","title":"Configurations"},{"location":"data_dictionaries/","text":"Data Dictionaries Data dictionaries should be created for each predictor and survey dataset. Dictionaries for the open-source data and Brazilian, Thai and Philippino survey data already exist and should be located in the data/meta/ folder. An exemplary data dictionary (for speedtest data) is shown below: Number Name Description Type Binary Role Use Comment 1 avg_d_kbps The average download speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 2 avg_u_kbps The average upload speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 3 avg_lat_ms The average latency of all tests performed in the tile, represented in milliseconds num N predictor N 4 tests The number of tests taken in the tile num N predictor N 5 devices The number of unique devices contributing tests in the tile num N predictor N","title":"Data Dictionaries"},{"location":"data_dictionaries/#data-dictionaries","text":"Data dictionaries should be created for each predictor and survey dataset. Dictionaries for the open-source data and Brazilian, Thai and Philippino survey data already exist and should be located in the data/meta/ folder. An exemplary data dictionary (for speedtest data) is shown below: Number Name Description Type Binary Role Use Comment 1 avg_d_kbps The average download speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 2 avg_u_kbps The average upload speed of all tests performed in the tile, represented in kilobits per second num N predictor Y mbps can also be used 3 avg_lat_ms The average latency of all tests performed in the tile, represented in milliseconds num N predictor N 4 tests The number of tests taken in the tile num N predictor N 5 devices The number of unique devices contributing tests in the tile num N predictor N","title":"Data Dictionaries"},{"location":"data_processing/","text":"Instructions to Create Model-Ready Dataset Create an environment from the requirements.txt file: 'pip install -r path/to/requirements.txt'. These package dependencies are only supported on Windows and Linux. Navigate to src/scripts/map_offline/. To generate a dataframe comprising any target variables and predictors that you wish to use, first set up the use case configurations in feature_engineering/configs.py. Details of the configurable variables and their expected assignments can be found in the 'configurations' section of the documentation. Having correctly set the desired configurations, all you need to do is run 'main.py'. Following this, a dataset for model training and/or application will be saved within a training_sets folder, which is situated within the data directory.","title":"Instructions to Create Model-Ready Dataset"},{"location":"data_processing/#instructions-to-create-model-ready-dataset","text":"Create an environment from the requirements.txt file: 'pip install -r path/to/requirements.txt'. These package dependencies are only supported on Windows and Linux. Navigate to src/scripts/map_offline/. To generate a dataframe comprising any target variables and predictors that you wish to use, first set up the use case configurations in feature_engineering/configs.py. Details of the configurable variables and their expected assignments can be found in the 'configurations' section of the documentation. Having correctly set the desired configurations, all you need to do is run 'main.py'. Following this, a dataset for model training and/or application will be saved within a training_sets folder, which is situated within the data directory.","title":"Instructions to Create Model-Ready Dataset"},{"location":"datagat/","text":"mermaid.initialize({startOnLoad:true}); mermaidAPI.initialize({ securityLevel: 'loose' }); Data Gathering Internal Data Surveys from ITU for Brazil and Thailand The target variable for our modeling was the proportion of a population around a particular school that was connected to the internet. It therefore ranged from 0-1, with 0 being zero percent connected and 100 being 100% connected to the internet. We chose to measure this on a school level as one of our objectives, through working with UNICEF, was to detect schools that could be connected to the internet and further serve the community they are located. Within the Brazil Survey data, we received information on household internet connectivity on an enumeration area level. This presented a slight challenge as the level of granularity of the school data was slightly different from the enumeration data or census tract. Thus, we matched the school points to the enumeration area data. We could not use all the school points as we only had enumeration areas for a specific amount of tracts in Brazil. Thus we had to subset our school points data to around 11,000 points. Once we connected the schools to the enumeration areas we were able to build our training data set. School Points from UNICEF for Brazil We got the school points in lat, long format from UNICEF for Brazil. Unfortunately, we were not able to obtain the school points for Thailand. We thus turned to OpenStreetMap to obtain school points for Thailand. We obtained many school points but filtered them to the schools that we were positive were schools as some were tagged as dance schools or even ATM's. Our school points script is thus specific for obtaining the OSM points. Should we say something about the licensing? External/Open Source Data Dataset Descriptions OpenCelliD Data OpenCelliD is a collaborative community project that collects GPS positions of cell towers and their corresponding location area identity. Dataset includes the locations and types of cell towers later which is used to calculate proximity of a tower to a school location. Each cell tower location contains following adjoining attributes: Parameter Description radio Network type. One of the strings GSM, UMTS, LTE or CDMA. mcc Mobile Country Code (UK: 234, 235) net Mobile Network Code (MNC) area Location Area Code (LAC) for GSM and UMTS networks. Tracking Area Code (TAC) for LTE networks. Network IDenfitication number (NID) for CDMA networks cell Cell ID unit Primary Scrambling Code (PSC) for UMTS networks. Physical Cell ID (PCI) for LTE networks. An empty value for GSM and CDMA networks lon Longitude in degrees between -180.0 and 180.0 If changeable=1: average of longitude values of all related measurements. If changeable=0: exact GPS position of the cell tower lat Latitude in degrees between -90.0 and 90.0 If changeable=1: average of latitude values of all related measurements. If changeable=0: exact GPS position of the tower range Estimate of cell range, in meters. samples Total number of measurements assigned to the cell tower changeable Defines if coordinates of the cell tower are exact or approximate. created The first time when the cell tower was seen and added to the OpenCellID database. updated The last time when the cell tower was seen and update. averageSignal Average signal strength from all assigned measurements for the cell. Population Data Population data is high-resolution geospatial data on population distributions. There are several types of gridded population count datasets in the WorldPop Open Population Repository (WOPR). In our data gathering pipeline we used Population Counts / Unconstrained individual countries 2000-2020 UN adjusted (1km resolution) datasets from WOPR. The dataset for individual countries is available in Geotiff and ASCII XYZ format at a resolution of 30 arc (approximately 1km at the equator). We used Geotiff image format as input and process the image to get population counts and locations for each pixel in the image. Each pixel contains the following adjoining attributes: Field Name Type Description population Float UN adjusted population count for the pixel location. geometry Geometry The geometry representing the pixel point location. Satellite Data To see the full code for gathering this data, click here. To gather the satellite data, we used Google Earth Engine API for Python. We gathered three different types of data: Global Human Modification Index, Nighttime Data, Normalized Difference Vegetation Index. Our hope with gathering this data is that it would provide an accurate proxy for households and schools with internet connection. If we knew a school was located in a place with a high average radiance, it might also mean there was high internet connectivity. The beauty of satellite data is that its continous for the entire globe. We initially struggled with learning how to crop the data for all the school points we wanted. Eventually, we set a buffer, 5 kilometers in our case, zone around each school point in both Brazil and Thailand and obtained specific satellite information that was input as a number into the training dataset. Below please find more information on each of the datasets we used including descriptions taken from the Google Earth Engine Data Catalog. Global Human Modification Index (String for Image Collection ID is: 'CSP/HM/GlobalHumanModification'): The global Human Modification dataset (gHM) provides a cumulative measure of human modification of terrestrial lands globally at 1 square-kilometer resolution. The gHM values range from 0.0-1.0 and are calculated by estimating the proportion of a given location (pixel) that is modified, the estimated intensity of modification associated with a given type of human modification or \"stressor\". 5 major anthropogenic stressors circa 2016 were mapped using 13 individual datasets: human settlement (population density, built-up areas) agriculture (cropland, livestock) transportation (major, minor, and two-track roads; railroads) mining and energy production electrical infrastructure (power lines, nighttime lights) NOAA Monthly Nighttime images using the VIIRS Satellite (String for Image Collection ID is: \"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\") Monthly average radiance composite images using nighttime data from the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB). As these data are composited monthly, there are many areas of the globe where it is impossible to get good quality data coverage for that month. This can be due to cloud cover, especially in the tropical regions, or due to solar illumination, as happens toward the poles in their respective summer months. Therefore it is recommended that users of these data utilize the 'cf_cvg' band and not assume a value of zero in the average radiance image means that no lights were observed. Normalized Difference Vegetation Index Band from the MODIS dataset (String for Image Collection ID is: 'MODIS/006/MOD13A2'): Normalized Difference Vegetation Index or NDVI measures the vegetation or greenness present on the Earth's surface The algorithm for this product chooses the best available pixel value from all the acquisitions from the 16-day period. The criteria used are low clouds, low view angle, and the highest NDVI/EVI value. Each school location contains the following adjoining attributes: Field Name Type Description mean_ghm Float The average global human modification index for the location and year 2016 mean_avg_rad Float The average radiance for the location and given start year and end year change_year_avg_rad Float The average yearly change of radiencebetween start year and end year for the location slope_year_avg_rad Float The average yearly slope of change of radiance between start year and end year for the location change_month_avg_rad Float The average monthly change of radiance between start year and end year for the location slope_month_avg_rad Float The average monthly slope of change of radiance between start year and end year for the location mean_cf_cvg Float The average cloud free coverage for the location and given start year and end year change_year_cf_cvg Float The average yearly change of cloud free coverage between start year and end year for the location slope_year_cf_cvg Float The average yearly slope of change of cloud free coverage between start year and end year for the location change_month_cf_cvg Float The average monthly change of cloud free coverage between start year and end year for the location slope_month_cf_cvg Float The average monthly slope of change of cloud free coverage between start year and end year for the location mean_NDVI Float The average NDVI for the location and given start year and end year change_year_NDVI Float The average yearly change of NDVI between start year and end year for the location slope_year_NDVI Float The average yearly slope of change of NDVI between start year and end year for the location change_month_NDVI Float The average monthly change of NDVI between start year and end year for the location slope_month_NDVI Float The average monthly slope of change of NDVI between start year and end year for the location Facebook Data Facebook data refers to the data that we get from Facebook Marketing API . The Marketing API is an HTTP-based API that you can use to programmatically query data, create and manage ads, and perform a wide variety of other tasks. Furthermore, our Facebook data mainly uses Ads Management API under Marketing API which has the method that provides delivery estimate for a given ad set configuration. Ad set refers to the collection of advertisements. For each ad set, it is possible to define delivery estimate using Ad Set Delivery Estimate method of the API. Two parameters are required for the delivery estimate method in order to get delivery estimate for a given location: optimization goal and dictionary that defines targeting specifications. Optimization goal can take several values such as 'clicks', 'impressions', 'replies', 'reach' etc. In our case, we used 'reach' as an optimization goal parameter since it carries out the 'Reach' objective to show ads to the maximum number of people in the area. On the other hand, targeting specification parameter is nicely customizable with fields such as 'geo-locations', 'interests', 'genders', 'age', 'relationship_status' and so on. In our case, we use custom locations (schools) with radius (5 kilometers) as our targeting specification and collect reach estimates for those locations. Each custom location contains the following adjoining attributes: Field Name Type Description estimate_dau Integer The estimated number of people that have been active on your selected platforms and satisfy your targeting spec in the past day. estimate_mau Integer The estimated number of people that have been active on your selected platforms and satisfy your targeting spec in the past month. estimate_ready Boolean Whether or not an estimate is ready for the audience. Some audiences require time to populate before we can provide a delivery estimate. Speedtest Data Speedtest data provides global fixed broadband and mobile (cellular) network performance metrics. The dataset provided by Ookla Open Data Projects in zoom level 16 web mercator tiles (approximately 610.8 meters by 610.8 meters at the equator). Data is provided in both Shapefile format as well as Apache Parquet with geometries represented in Well Known Text (WKT) projected in EPSG:4326. Download speed, upload speed, and latency are collected via the Speedtest by Ookla applications and averaged for each tile. Each tile contains the following adjoining attributes: Field Name Type Description avg_d_kbps Integer The average download speed of all tests performed in the tile, represented in kilobits per second. avg_u_kbps Integer The average upload speed of all tests performed in the tile, represented in kilobits per second. avg_lat_ms Integer The average latency of all tests performed in the tile, represented in milliseconds tests Integer The number of tests taken in the tile. devices Integer The number of unique devices contributing tests in the tile. quadkey Text The quadkey representing the tile. geometry Geometry The geometry representing the tile location and shape. Data Gathering and Feature Engineering Class Diagram Our data pipeline includes three superclasses: Country, Opendata and Feature Engineering. Country is a parent class to our school and survey classes. Opendata class is a parent class to speedtest, opencell, facebook, population and satellite open-source data classes. Finally, we coded feature engineering class in which school, survey and opendata classes are processed and merged. Map Offline Package Hierarchy: classDiagram map_offline < |-- OpenData map_offline < |-- FeatureEngineering map_offline < |-- Country Country < |-- School Country < |-- Survey Survey < |-- BRA_Survey Survey < |-- THA_Survey Survey < |-- PHL_Survey OpenData < |-- PopulationData OpenData < |-- SpeedtestData OpenData < |-- FacebookData OpenData < |-- OpencellData OpenData < |-- SatelliteData class map_offline{ +training_set_vxxx } class FeatureEngineering{ + configs + school_data + set_training_data() + save_training_set() + get_opendata() } class Country{ + country_code + country_name + geodata + set_country_geometry() } class School{ + buffer + data + set_school_data() } class Survey{ + available_countries + data } class BRA_Survey{ + set_survey_data() } class THA_Survey{ + set_survey_data() } class PHL_Survey{ + set_survey_data() } class OpenData{ + country_code + data } class PopulationData{ + year + set_pop_data() } class SpeedtestData{ + type + year + quarter + set_speedtest_data() } class FacebookData{ + locations + access_token + ad_account_id + call_limit + radius + set_fb_data() } class OpencellData{ + access_token + set_cell_data() } class SatelliteData{ + locations + start_year + end_year + buffer + max_call_size + json_key_path + ee_service_account + set_satellite_data() } Data Gathering Pipeline We are still working on the data gathering pipeline workflow... OpencellData PopulationData SatelliteData FacebookData SpeedtestData Training Data Dictionary Show a table of each of the predictor in the training set and what their definitions are: Variable Name Description Data Source avg_d_kbps Average Download Speed Speedtest Data avg_u_kbps Average Upload Speed Speedtest Data estimate_dau Facebook Daily Active Users estimate Facebook Data estimate_mau Facebook Monthly Active Users estimate Facebook Data population Population around school buffer zone Population Data mean_ghm Mean Global Human Modification value Satellite Data - Global Human Modification Index mean_avg_rad Mean value from the Average Radiance band Satellite Data - VIIRS Nighttime DNB mean_cf_cvg Mean value from the cloud free coverage band Satellite Data - VIIRS Nighttime DNB slope_year_avg_rad The yearly rate of change between 2019 and 2014 of Average Radiance Satellite Data - VIIRS Nighttime DNB change_year_avg_rad The change between the average values of 2019 and 2014 of Average Radiance Satellite Data - VIIRS Nighttime DNB slope_year_cf_cvg The yearly rate of change between 2019 and 2014 from the Cloud Free Coverage Band Satellite Data - VIIRS Nighttime DNB change_year_cf_cvg The change between the average values of 2019 and 2014 from the Cloud Free Coverage Band Satellite Data - VIIRS Nighttime DNB slope_month_avg_rad The monthly rate of change between 2019 and 2014 of the Average Radiance Band Satellite Data - VIIRS Nighttime DNB change_month_avg_rad The change between the average of Dec 2019 and Jan 2014 of the Average Radiance Band Satellite Data - VIIRS Nighttime DNB slope_month_cf_cvg The monthly rate of change between 2019 and 2014 from the Cloud Free Coverage Band Satellite Data - VIIRS Nighttime DNB change_month_cf_cvg The rate of change between the average of Dec 2019 and Jan 2014 from the Cloud Free Coverage Band Satellite Data - VIIRS Nighttime DNB mean_NDVI The average value of the Vegetation Index Satellite Data - MODIS Dataset slope_year_NDVI The yearly rate of change between 2019 and 2014 of the Vegetation Index Satellite Data - MODIS Dataset change_year_NDVI The change between 2019 and 2014 of the Vegetation Index Satellite Data - MODIS Dataset slope_month_NDVI The monthly rate of change between 2019 and 2014 of the Vegetation Index Satellite Data - MODIS Dataset change_month_NDVI The change between the average of May 2019 and May 2014 of the Vegetation Index Satellite Data - MODIS Dataset range The binary variable that checks whether there is opencell tower in the to the school area OpenCelliD Data","title":"Data Gathering"},{"location":"datagat/#data-gathering","text":"","title":"Data Gathering"},{"location":"datagat/#internal-data","text":"Surveys from ITU for Brazil and Thailand The target variable for our modeling was the proportion of a population around a particular school that was connected to the internet. It therefore ranged from 0-1, with 0 being zero percent connected and 100 being 100% connected to the internet. We chose to measure this on a school level as one of our objectives, through working with UNICEF, was to detect schools that could be connected to the internet and further serve the community they are located. Within the Brazil Survey data, we received information on household internet connectivity on an enumeration area level. This presented a slight challenge as the level of granularity of the school data was slightly different from the enumeration data or census tract. Thus, we matched the school points to the enumeration area data. We could not use all the school points as we only had enumeration areas for a specific amount of tracts in Brazil. Thus we had to subset our school points data to around 11,000 points. Once we connected the schools to the enumeration areas we were able to build our training data set. School Points from UNICEF for Brazil We got the school points in lat, long format from UNICEF for Brazil. Unfortunately, we were not able to obtain the school points for Thailand. We thus turned to OpenStreetMap to obtain school points for Thailand. We obtained many school points but filtered them to the schools that we were positive were schools as some were tagged as dance schools or even ATM's. Our school points script is thus specific for obtaining the OSM points. Should we say something about the licensing?","title":"Internal Data"},{"location":"datagat/#externalopen-source-data","text":"","title":"External/Open Source Data"},{"location":"datagat/#dataset-descriptions","text":"OpenCelliD Data OpenCelliD is a collaborative community project that collects GPS positions of cell towers and their corresponding location area identity. Dataset includes the locations and types of cell towers later which is used to calculate proximity of a tower to a school location. Each cell tower location contains following adjoining attributes: Parameter Description radio Network type. One of the strings GSM, UMTS, LTE or CDMA. mcc Mobile Country Code (UK: 234, 235) net Mobile Network Code (MNC) area Location Area Code (LAC) for GSM and UMTS networks. Tracking Area Code (TAC) for LTE networks. Network IDenfitication number (NID) for CDMA networks cell Cell ID unit Primary Scrambling Code (PSC) for UMTS networks. Physical Cell ID (PCI) for LTE networks. An empty value for GSM and CDMA networks lon Longitude in degrees between -180.0 and 180.0 If changeable=1: average of longitude values of all related measurements. If changeable=0: exact GPS position of the cell tower lat Latitude in degrees between -90.0 and 90.0 If changeable=1: average of latitude values of all related measurements. If changeable=0: exact GPS position of the tower range Estimate of cell range, in meters. samples Total number of measurements assigned to the cell tower changeable Defines if coordinates of the cell tower are exact or approximate. created The first time when the cell tower was seen and added to the OpenCellID database. updated The last time when the cell tower was seen and update. averageSignal Average signal strength from all assigned measurements for the cell. Population Data Population data is high-resolution geospatial data on population distributions. There are several types of gridded population count datasets in the WorldPop Open Population Repository (WOPR). In our data gathering pipeline we used Population Counts / Unconstrained individual countries 2000-2020 UN adjusted (1km resolution) datasets from WOPR. The dataset for individual countries is available in Geotiff and ASCII XYZ format at a resolution of 30 arc (approximately 1km at the equator). We used Geotiff image format as input and process the image to get population counts and locations for each pixel in the image. Each pixel contains the following adjoining attributes: Field Name Type Description population Float UN adjusted population count for the pixel location. geometry Geometry The geometry representing the pixel point location. Satellite Data To see the full code for gathering this data, click here. To gather the satellite data, we used Google Earth Engine API for Python. We gathered three different types of data: Global Human Modification Index, Nighttime Data, Normalized Difference Vegetation Index. Our hope with gathering this data is that it would provide an accurate proxy for households and schools with internet connection. If we knew a school was located in a place with a high average radiance, it might also mean there was high internet connectivity. The beauty of satellite data is that its continous for the entire globe. We initially struggled with learning how to crop the data for all the school points we wanted. Eventually, we set a buffer, 5 kilometers in our case, zone around each school point in both Brazil and Thailand and obtained specific satellite information that was input as a number into the training dataset. Below please find more information on each of the datasets we used including descriptions taken from the Google Earth Engine Data Catalog. Global Human Modification Index (String for Image Collection ID is: 'CSP/HM/GlobalHumanModification'): The global Human Modification dataset (gHM) provides a cumulative measure of human modification of terrestrial lands globally at 1 square-kilometer resolution. The gHM values range from 0.0-1.0 and are calculated by estimating the proportion of a given location (pixel) that is modified, the estimated intensity of modification associated with a given type of human modification or \"stressor\". 5 major anthropogenic stressors circa 2016 were mapped using 13 individual datasets: human settlement (population density, built-up areas) agriculture (cropland, livestock) transportation (major, minor, and two-track roads; railroads) mining and energy production electrical infrastructure (power lines, nighttime lights) NOAA Monthly Nighttime images using the VIIRS Satellite (String for Image Collection ID is: \"NOAA/VIIRS/DNB/MONTHLY_V1/VCMSLCFG\") Monthly average radiance composite images using nighttime data from the Visible Infrared Imaging Radiometer Suite (VIIRS) Day/Night Band (DNB). As these data are composited monthly, there are many areas of the globe where it is impossible to get good quality data coverage for that month. This can be due to cloud cover, especially in the tropical regions, or due to solar illumination, as happens toward the poles in their respective summer months. Therefore it is recommended that users of these data utilize the 'cf_cvg' band and not assume a value of zero in the average radiance image means that no lights were observed. Normalized Difference Vegetation Index Band from the MODIS dataset (String for Image Collection ID is: 'MODIS/006/MOD13A2'): Normalized Difference Vegetation Index or NDVI measures the vegetation or greenness present on the Earth's surface The algorithm for this product chooses the best available pixel value from all the acquisitions from the 16-day period. The criteria used are low clouds, low view angle, and the highest NDVI/EVI value. Each school location contains the following adjoining attributes: Field Name Type Description mean_ghm Float The average global human modification index for the location and year 2016 mean_avg_rad Float The average radiance for the location and given start year and end year change_year_avg_rad Float The average yearly change of radiencebetween start year and end year for the location slope_year_avg_rad Float The average yearly slope of change of radiance between start year and end year for the location change_month_avg_rad Float The average monthly change of radiance between start year and end year for the location slope_month_avg_rad Float The average monthly slope of change of radiance between start year and end year for the location mean_cf_cvg Float The average cloud free coverage for the location and given start year and end year change_year_cf_cvg Float The average yearly change of cloud free coverage between start year and end year for the location slope_year_cf_cvg Float The average yearly slope of change of cloud free coverage between start year and end year for the location change_month_cf_cvg Float The average monthly change of cloud free coverage between start year and end year for the location slope_month_cf_cvg Float The average monthly slope of change of cloud free coverage between start year and end year for the location mean_NDVI Float The average NDVI for the location and given start year and end year change_year_NDVI Float The average yearly change of NDVI between start year and end year for the location slope_year_NDVI Float The average yearly slope of change of NDVI between start year and end year for the location change_month_NDVI Float The average monthly change of NDVI between start year and end year for the location slope_month_NDVI Float The average monthly slope of change of NDVI between start year and end year for the location Facebook Data Facebook data refers to the data that we get from Facebook Marketing API . The Marketing API is an HTTP-based API that you can use to programmatically query data, create and manage ads, and perform a wide variety of other tasks. Furthermore, our Facebook data mainly uses Ads Management API under Marketing API which has the method that provides delivery estimate for a given ad set configuration. Ad set refers to the collection of advertisements. For each ad set, it is possible to define delivery estimate using Ad Set Delivery Estimate method of the API. Two parameters are required for the delivery estimate method in order to get delivery estimate for a given location: optimization goal and dictionary that defines targeting specifications. Optimization goal can take several values such as 'clicks', 'impressions', 'replies', 'reach' etc. In our case, we used 'reach' as an optimization goal parameter since it carries out the 'Reach' objective to show ads to the maximum number of people in the area. On the other hand, targeting specification parameter is nicely customizable with fields such as 'geo-locations', 'interests', 'genders', 'age', 'relationship_status' and so on. In our case, we use custom locations (schools) with radius (5 kilometers) as our targeting specification and collect reach estimates for those locations. Each custom location contains the following adjoining attributes: Field Name Type Description estimate_dau Integer The estimated number of people that have been active on your selected platforms and satisfy your targeting spec in the past day. estimate_mau Integer The estimated number of people that have been active on your selected platforms and satisfy your targeting spec in the past month. estimate_ready Boolean Whether or not an estimate is ready for the audience. Some audiences require time to populate before we can provide a delivery estimate. Speedtest Data Speedtest data provides global fixed broadband and mobile (cellular) network performance metrics. The dataset provided by Ookla Open Data Projects in zoom level 16 web mercator tiles (approximately 610.8 meters by 610.8 meters at the equator). Data is provided in both Shapefile format as well as Apache Parquet with geometries represented in Well Known Text (WKT) projected in EPSG:4326. Download speed, upload speed, and latency are collected via the Speedtest by Ookla applications and averaged for each tile. Each tile contains the following adjoining attributes: Field Name Type Description avg_d_kbps Integer The average download speed of all tests performed in the tile, represented in kilobits per second. avg_u_kbps Integer The average upload speed of all tests performed in the tile, represented in kilobits per second. avg_lat_ms Integer The average latency of all tests performed in the tile, represented in milliseconds tests Integer The number of tests taken in the tile. devices Integer The number of unique devices contributing tests in the tile. quadkey Text The quadkey representing the tile. geometry Geometry The geometry representing the tile location and shape.","title":"Dataset Descriptions"},{"location":"datagat/#data-gathering-and-feature-engineering-class-diagram","text":"Our data pipeline includes three superclasses: Country, Opendata and Feature Engineering. Country is a parent class to our school and survey classes. Opendata class is a parent class to speedtest, opencell, facebook, population and satellite open-source data classes. Finally, we coded feature engineering class in which school, survey and opendata classes are processed and merged.","title":"Data Gathering and Feature Engineering Class Diagram"},{"location":"datagat/#map-offline-package-hierarchy","text":"classDiagram map_offline < |-- OpenData map_offline < |-- FeatureEngineering map_offline < |-- Country Country < |-- School Country < |-- Survey Survey < |-- BRA_Survey Survey < |-- THA_Survey Survey < |-- PHL_Survey OpenData < |-- PopulationData OpenData < |-- SpeedtestData OpenData < |-- FacebookData OpenData < |-- OpencellData OpenData < |-- SatelliteData class map_offline{ +training_set_vxxx } class FeatureEngineering{ + configs + school_data + set_training_data() + save_training_set() + get_opendata() } class Country{ + country_code + country_name + geodata + set_country_geometry() } class School{ + buffer + data + set_school_data() } class Survey{ + available_countries + data } class BRA_Survey{ + set_survey_data() } class THA_Survey{ + set_survey_data() } class PHL_Survey{ + set_survey_data() } class OpenData{ + country_code + data } class PopulationData{ + year + set_pop_data() } class SpeedtestData{ + type + year + quarter + set_speedtest_data() } class FacebookData{ + locations + access_token + ad_account_id + call_limit + radius + set_fb_data() } class OpencellData{ + access_token + set_cell_data() } class SatelliteData{ + locations + start_year + end_year + buffer + max_call_size + json_key_path + ee_service_account + set_satellite_data() }","title":"Map Offline Package Hierarchy:"},{"location":"datagat/#data-gathering-pipeline","text":"We are still working on the data gathering pipeline workflow... OpencellData PopulationData SatelliteData FacebookData SpeedtestData","title":"Data Gathering Pipeline"},{"location":"datagat/#training-data-dictionary","text":"Show a table of each of the predictor in the training set and what their definitions are: Variable Name Description Data Source avg_d_kbps Average Download Speed Speedtest Data avg_u_kbps Average Upload Speed Speedtest Data estimate_dau Facebook Daily Active Users estimate Facebook Data estimate_mau Facebook Monthly Active Users estimate Facebook Data population Population around school buffer zone Population Data mean_ghm Mean Global Human Modification value Satellite Data - Global Human Modification Index mean_avg_rad Mean value from the Average Radiance band Satellite Data - VIIRS Nighttime DNB mean_cf_cvg Mean value from the cloud free coverage band Satellite Data - VIIRS Nighttime DNB slope_year_avg_rad The yearly rate of change between 2019 and 2014 of Average Radiance Satellite Data - VIIRS Nighttime DNB change_year_avg_rad The change between the average values of 2019 and 2014 of Average Radiance Satellite Data - VIIRS Nighttime DNB slope_year_cf_cvg The yearly rate of change between 2019 and 2014 from the Cloud Free Coverage Band Satellite Data - VIIRS Nighttime DNB change_year_cf_cvg The change between the average values of 2019 and 2014 from the Cloud Free Coverage Band Satellite Data - VIIRS Nighttime DNB slope_month_avg_rad The monthly rate of change between 2019 and 2014 of the Average Radiance Band Satellite Data - VIIRS Nighttime DNB change_month_avg_rad The change between the average of Dec 2019 and Jan 2014 of the Average Radiance Band Satellite Data - VIIRS Nighttime DNB slope_month_cf_cvg The monthly rate of change between 2019 and 2014 from the Cloud Free Coverage Band Satellite Data - VIIRS Nighttime DNB change_month_cf_cvg The rate of change between the average of Dec 2019 and Jan 2014 from the Cloud Free Coverage Band Satellite Data - VIIRS Nighttime DNB mean_NDVI The average value of the Vegetation Index Satellite Data - MODIS Dataset slope_year_NDVI The yearly rate of change between 2019 and 2014 of the Vegetation Index Satellite Data - MODIS Dataset change_year_NDVI The change between 2019 and 2014 of the Vegetation Index Satellite Data - MODIS Dataset slope_month_NDVI The monthly rate of change between 2019 and 2014 of the Vegetation Index Satellite Data - MODIS Dataset change_month_NDVI The change between the average of May 2019 and May 2014 of the Vegetation Index Satellite Data - MODIS Dataset range The binary variable that checks whether there is opencell tower in the to the school area OpenCelliD Data","title":"Training Data Dictionary"},{"location":"eda/","text":"Exploratory Data Analysis As a disclaimer, some of this EDA is to explore our raw data and what it looks like. However, to run these notebooks, especially with using the satellite data and school points you will already need to run the Data Gathering and Feature Engineering Scripts first. Satellite Data The first thing we wanted to explore in our Exploratory Data Analysis was some maps of what our countries looked like and how our predictors might map onto our countries. We used Google Earth Engine to create some maps of nighttime imagery, the global human modification index and the vegetation index. For nighttime and vegetation index, we also wanted to show the change in time as we were using the rate of change as a predictor as well. Below you will find some static images of the maps we created. If you click on them, you can also find an interactive version. Click here to see the Jupyter notebook with code included for replicating the maps below. Satellite Images on a National Level for both Brazil and Thailand: Average Radiance Band Here we see that the Average light comes from the big cities in the south for both countries. This predictor later plays a big role in determining internet connectivity. Click on this map to see a comparison between school points and the entire country average radiance in 2014 and in 2019. Cloud Free Band This is a second band within the VIIRS Satellite nighttime images. It measures light without clouds or solar illumination. In some ways, specifically in tropical rainforests which both Brazil and Thailand have, it is a better measure of light emittance than the average radiance band. We use both as predictors in our model. Additionally, you see in the maps that the light emittance looks vastly different. Click on this map to see a comparison between school points and the entire country cloud free coverage in 2014 and in 2019. Global Human Modification Map In this map, we see the level of Global Human Modification in the last few years within both Brazil and Thailand. For more information on how this dataset was compiled, please see the Data Gathering page. Click on this Brazil Map to see the country level data. Normalized Difference Vegetation Index Here we see the difference in vegetation between Brazil and Thailand. Click here to see the map for Brazil, toggle between the layers to see the entire country and just the school point areas. Here we also see GIFs that show the time series change of vegetation from 2000 to 2021. Speedtest data Open Cell ID data Facebook Data Training Set EDA We also did some Exploratory Data Analysis once our training dataset was created. You will not be able to run this on your own until you have run the Data Gathering and Feature Engineering scripts. Click Here for the full notebook of explanatory visualizations. Click here for the Jupyter Notebook .ipynb file.","title":"Exploratory Data Analysis"},{"location":"eda/#exploratory-data-analysis","text":"As a disclaimer, some of this EDA is to explore our raw data and what it looks like. However, to run these notebooks, especially with using the satellite data and school points you will already need to run the Data Gathering and Feature Engineering Scripts first.","title":"Exploratory Data Analysis"},{"location":"eda/#satellite-data","text":"The first thing we wanted to explore in our Exploratory Data Analysis was some maps of what our countries looked like and how our predictors might map onto our countries. We used Google Earth Engine to create some maps of nighttime imagery, the global human modification index and the vegetation index. For nighttime and vegetation index, we also wanted to show the change in time as we were using the rate of change as a predictor as well. Below you will find some static images of the maps we created. If you click on them, you can also find an interactive version. Click here to see the Jupyter notebook with code included for replicating the maps below. Satellite Images on a National Level for both Brazil and Thailand: Average Radiance Band Here we see that the Average light comes from the big cities in the south for both countries. This predictor later plays a big role in determining internet connectivity. Click on this map to see a comparison between school points and the entire country average radiance in 2014 and in 2019. Cloud Free Band This is a second band within the VIIRS Satellite nighttime images. It measures light without clouds or solar illumination. In some ways, specifically in tropical rainforests which both Brazil and Thailand have, it is a better measure of light emittance than the average radiance band. We use both as predictors in our model. Additionally, you see in the maps that the light emittance looks vastly different. Click on this map to see a comparison between school points and the entire country cloud free coverage in 2014 and in 2019. Global Human Modification Map In this map, we see the level of Global Human Modification in the last few years within both Brazil and Thailand. For more information on how this dataset was compiled, please see the Data Gathering page. Click on this Brazil Map to see the country level data. Normalized Difference Vegetation Index Here we see the difference in vegetation between Brazil and Thailand. Click here to see the map for Brazil, toggle between the layers to see the entire country and just the school point areas. Here we also see GIFs that show the time series change of vegetation from 2000 to 2021.","title":"Satellite Data"},{"location":"eda/#speedtest-data","text":"","title":"Speedtest data"},{"location":"eda/#open-cell-id-data","text":"","title":"Open Cell ID data"},{"location":"eda/#facebook-data","text":"","title":"Facebook Data"},{"location":"eda/#training-set-eda","text":"We also did some Exploratory Data Analysis once our training dataset was created. You will not be able to run this on your own until you have run the Data Gathering and Feature Engineering scripts. Click Here for the full notebook of explanatory visualizations. Click here for the Jupyter Notebook .ipynb file.","title":"Training Set EDA"},{"location":"fe/","text":"mermaid.initialize({startOnLoad:true}); mermaidAPI.initialize({ securityLevel: 'loose' }); Feature Engineering Having retrieved data of many different types, at different geospatial resolutions, from an array of different sources, it was necessary to develop a robust and comprehensive feature engineering pipeline, which produces clean datasets, ready for model training or application. Data Cleaning Numerical Variables - Impute missing values as variable median. Categorical Variables - Fill missing values with 'missing' label; perform one-hot encoding. Target Variable Our target variable is ground-truth survey data on local internet connectivity. For the Brazilian and Thai surveys, fowarded to us by ITU, these target variables correspond to the following labels: Brazil - A4A Thailand - H107 In each case, we rename our target variable to simply 'target'. Joining Locations In the following description, we use the word 'feature' to mean predictor and, in some cases, ground truth survey variable. The map_feature method within the FeatureEngineering class is used to perform a spatial join between school locations and feature values. In essence, we are finding the correct value of each feature at each given school location. To do so, we first ensure that the dataframe corresponding to each predictor or survey dataset is loaded as a geodataframe, with an appropriately defined 'geometry' column. If the feature's geometry is a polygon, or multipolygon, rather than a point, we take the centroid as the location with which to match. If, instead, the feature's geometry is defined by latitude and longitude columns, rather than a single geometry column, this will be handled appropriately, so long as these column names are exactly 'latitude' and 'longitude', or 'lat' and 'lon'. For the unexpected instance in which schools have already been matched to feature values, we look for a 'source_school_id' column and merge the school data to the feature data according to these school ids. This is for the sake of code robustness, in case features that are already mapped to schools are mistakenly passed to the map_feature method. The build_tree method is then called to implement Scikit-learn's KDTree package and thus build a kd tree of the previously defined centroids. The kd tree is a tree in k-dimensional space; for us, this defines the spatial relationships between locations. This tree is then queried with the school locations to get the nearest neighbours, with the query returning dist (geographic distance) and ind (index associated with this location). The rows in the school_data dataframe are then assigned the correct values for each new column. For any variable named 'range', such as the mobile cell tower range variable from the OpenCellID dataset, values are converted to a 0 or 1, corresponding to range < dist and range >= dist respectively. This last part converts any 'range' to a binary variable, representing out-of-range, or in-range. If Dataset Is Sparsely Scattered across Country: It should be noted that the map_feature method should only be used for features that are not sparsely distributed. For example, this method is not used for the Brazil survey data, which is only available for a selection of enumeration areas, which often have significant geographic regions between them. For other features, such as the Brazil survey data, which have values only in sparsely distributed locations, we employ the map_enumeration method, which joins school locations to areas via intersections between the enumeration area polygons and 1km radius school buffer zones. We then check for instances in which a school might have been joined to multiple enumeration areas and select only the nearest enumeration area for such cases. High Level Feature Engineering Pipeline graph TD A[Get School Data] --> B{Is Survey Available?}; B --> |Yes| C[Get Survey Data]; B --> |No| D[Load Predictor Dataset]; C --> E D --> E[Initialise New Columns]; E --> F[Clean New Data]; F --> G[Match New Data to Schools]; G --> H{All Features Added?}; H --> |Yes| I[Save Dataset] H --> |No| D; Classification Use Case Should you wish to train or apply a classifier, instead of a regression model, you can create a binary classification dataset by running the 'binning.py' script, found in the src/scripts/ folder. Within this script, it is straightforward to edit the name of a standard regression training dataset that you wish to convert into a classification-ready dataset. To train/apply a classification model, one would then simply need to change the dataset file name within the 'configs.yml' file.","title":"Feature Engineering"},{"location":"fe/#feature-engineering","text":"Having retrieved data of many different types, at different geospatial resolutions, from an array of different sources, it was necessary to develop a robust and comprehensive feature engineering pipeline, which produces clean datasets, ready for model training or application.","title":"Feature Engineering"},{"location":"fe/#data-cleaning","text":"Numerical Variables - Impute missing values as variable median. Categorical Variables - Fill missing values with 'missing' label; perform one-hot encoding.","title":"Data Cleaning"},{"location":"fe/#target-variable","text":"Our target variable is ground-truth survey data on local internet connectivity. For the Brazilian and Thai surveys, fowarded to us by ITU, these target variables correspond to the following labels: Brazil - A4A Thailand - H107 In each case, we rename our target variable to simply 'target'.","title":"Target Variable"},{"location":"fe/#joining-locations","text":"In the following description, we use the word 'feature' to mean predictor and, in some cases, ground truth survey variable. The map_feature method within the FeatureEngineering class is used to perform a spatial join between school locations and feature values. In essence, we are finding the correct value of each feature at each given school location. To do so, we first ensure that the dataframe corresponding to each predictor or survey dataset is loaded as a geodataframe, with an appropriately defined 'geometry' column. If the feature's geometry is a polygon, or multipolygon, rather than a point, we take the centroid as the location with which to match. If, instead, the feature's geometry is defined by latitude and longitude columns, rather than a single geometry column, this will be handled appropriately, so long as these column names are exactly 'latitude' and 'longitude', or 'lat' and 'lon'. For the unexpected instance in which schools have already been matched to feature values, we look for a 'source_school_id' column and merge the school data to the feature data according to these school ids. This is for the sake of code robustness, in case features that are already mapped to schools are mistakenly passed to the map_feature method. The build_tree method is then called to implement Scikit-learn's KDTree package and thus build a kd tree of the previously defined centroids. The kd tree is a tree in k-dimensional space; for us, this defines the spatial relationships between locations. This tree is then queried with the school locations to get the nearest neighbours, with the query returning dist (geographic distance) and ind (index associated with this location). The rows in the school_data dataframe are then assigned the correct values for each new column. For any variable named 'range', such as the mobile cell tower range variable from the OpenCellID dataset, values are converted to a 0 or 1, corresponding to range < dist and range >= dist respectively. This last part converts any 'range' to a binary variable, representing out-of-range, or in-range.","title":"Joining Locations"},{"location":"fe/#if-dataset-is-sparsely-scattered-across-country","text":"It should be noted that the map_feature method should only be used for features that are not sparsely distributed. For example, this method is not used for the Brazil survey data, which is only available for a selection of enumeration areas, which often have significant geographic regions between them. For other features, such as the Brazil survey data, which have values only in sparsely distributed locations, we employ the map_enumeration method, which joins school locations to areas via intersections between the enumeration area polygons and 1km radius school buffer zones. We then check for instances in which a school might have been joined to multiple enumeration areas and select only the nearest enumeration area for such cases.","title":"If Dataset Is Sparsely Scattered across Country:"},{"location":"fe/#high-level-feature-engineering-pipeline","text":"graph TD A[Get School Data] --> B{Is Survey Available?}; B --> |Yes| C[Get Survey Data]; B --> |No| D[Load Predictor Dataset]; C --> E D --> E[Initialise New Columns]; E --> F[Clean New Data]; F --> G[Match New Data to Schools]; G --> H{All Features Added?}; H --> |Yes| I[Save Dataset] H --> |No| D;","title":"High Level Feature Engineering Pipeline"},{"location":"fe/#classification-use-case","text":"Should you wish to train or apply a classifier, instead of a regression model, you can create a binary classification dataset by running the 'binning.py' script, found in the src/scripts/ folder. Within this script, it is straightforward to edit the name of a standard regression training dataset that you wish to convert into a classification-ready dataset. To train/apply a classification model, one would then simply need to change the dataset file name within the 'configs.yml' file.","title":"Classification Use Case"},{"location":"folder_structure/","text":"Folder Structure conf/ data/ geodata/ meta/ school_loc/ fb/ opencellid/ satellite/ speedtest/ survey/ Brazil/ Thailand/ Philippines/ training_sets/ Brazil/ Thailand/ Philippines/ worldpop/ model/ notebooks/ src/ scripts/ map_offline data_gathering init .py opendata.py opendata_utils.py opendata_scrap.py opendata_facebook.py opendata_satellite.py feature_engineering init .py data_pipeline.py configs.py country.py survey.py school.py main.py requirements.txt","title":"Folder Structure"},{"location":"folder_structure/#folder-structure","text":"conf/ data/ geodata/ meta/ school_loc/ fb/ opencellid/ satellite/ speedtest/ survey/ Brazil/ Thailand/ Philippines/ training_sets/ Brazil/ Thailand/ Philippines/ worldpop/ model/ notebooks/ src/ scripts/ map_offline data_gathering init .py opendata.py opendata_utils.py opendata_scrap.py opendata_facebook.py opendata_satellite.py feature_engineering init .py data_pipeline.py configs.py country.py survey.py school.py main.py requirements.txt","title":"Folder Structure"},{"location":"intro/","text":"Introduction Motivation To date, just six out of ten people around the globe have access to the internet. In today's fast paced, digital world, being offline excludes individuals from large parts of social and economic life. The capabilities of the internet surmount mere communication, as the internet grants access to global knowledge, political participation and new economic arenas. The world wide web is widely understood as a crucial backbone to human and economic development. As such, the Giga Initiative, originated by the International Telecommunication Union (ITU) and UNICEF, has set its goal to connect every school to the internet by 2030. Giving students the opportunity to access and explore the internet prevents transferring inequalities to the future, as basic online knowledge and skills are essential to participate and thrive in a globalized society. In addition, schools often serve as community hubs for the surrounding local population. The internet connectivity provided by a school is therefore capable of helping an entire community in their economic development. Using the internet necessarily requires an internet-enabled device and electricity, however individuals might not have the resources for this investment. Being able to use a school's internet devices can yield basic connectivity for a large number of people. Nevertheless, connecting schools in random order (e.g. from A to Z) does not allocate resources where they are most needed or in the most efficient manner. Connecting schools that are most visible, or those that actively apply for a connection, could even aggravate disparities within a country, since offline communities are typically hard-to-target or even identify. Therefore, our project aims to provide a reasonable priorization mechanism to determine which schools' connection would positively affect the largest number of individuals. Use Case Our project has multiple objectives. First, we aim to determine the share of households/individuals with internet connectivity around a school. Internet connectivity, in this instance, is defined as any ability to get online. This includes both broadband and mobile internet connection. It also means that individuals must have devices that can connect to the internet. An absence of any of these things would result in an individual or household who is not connected. The next objective is taking the absolute population number around the school in order to estimate the associated offline population. We can then provide a list of all schools prioritized by the ones that most require internet access and have the highest amount of people that would benefit. Possibly even the feasability of connection could be regarded in this process, as previous school location databases have had information on computer availability in a school. It should be easier to provide schools that already have electricity and computers with access to the internet. Our third objective, and one which was requested by ITU, is to aggregate our understanding of internet connectivity on a school level up to a country level. While this might already exist for many countries, a national level aggregation will be helpful in countries where there are currently no surveys or established statistics on internet connectivity. Furthermore, a prediction from a robust and generalizable model has the potential to be even more accurate, or more complete than a national survey. Our model can establish a baseline metric for a country and build a greater understanding of countries that have low or high internet connectivity. The geographical nature of analysis also makes it possible to detect regional and local differences within countries themselves. Ultimately, we are contributing to the field of offline population research as well as global human development. Our model and approach offers fruitful insights into which features and models are most efficient in predicting internet connectivity. Hopefully, our results can be used by researchers and organizations. Within this site, you will find a documentation of our process and analysis as well as a discussion of our findings. Our aim is for this to be as reproducible as possible for other countries and we hope that it can be used for building a greater understanding of internet connectivity. While we link to scripts throughout, a full collection of scripts and documentation can be cloned via the GitHub repository here .","title":"Introduction"},{"location":"intro/#introduction","text":"","title":"Introduction"},{"location":"intro/#motivation","text":"To date, just six out of ten people around the globe have access to the internet. In today's fast paced, digital world, being offline excludes individuals from large parts of social and economic life. The capabilities of the internet surmount mere communication, as the internet grants access to global knowledge, political participation and new economic arenas. The world wide web is widely understood as a crucial backbone to human and economic development. As such, the Giga Initiative, originated by the International Telecommunication Union (ITU) and UNICEF, has set its goal to connect every school to the internet by 2030. Giving students the opportunity to access and explore the internet prevents transferring inequalities to the future, as basic online knowledge and skills are essential to participate and thrive in a globalized society. In addition, schools often serve as community hubs for the surrounding local population. The internet connectivity provided by a school is therefore capable of helping an entire community in their economic development. Using the internet necessarily requires an internet-enabled device and electricity, however individuals might not have the resources for this investment. Being able to use a school's internet devices can yield basic connectivity for a large number of people. Nevertheless, connecting schools in random order (e.g. from A to Z) does not allocate resources where they are most needed or in the most efficient manner. Connecting schools that are most visible, or those that actively apply for a connection, could even aggravate disparities within a country, since offline communities are typically hard-to-target or even identify. Therefore, our project aims to provide a reasonable priorization mechanism to determine which schools' connection would positively affect the largest number of individuals.","title":"Motivation"},{"location":"intro/#use-case","text":"Our project has multiple objectives. First, we aim to determine the share of households/individuals with internet connectivity around a school. Internet connectivity, in this instance, is defined as any ability to get online. This includes both broadband and mobile internet connection. It also means that individuals must have devices that can connect to the internet. An absence of any of these things would result in an individual or household who is not connected. The next objective is taking the absolute population number around the school in order to estimate the associated offline population. We can then provide a list of all schools prioritized by the ones that most require internet access and have the highest amount of people that would benefit. Possibly even the feasability of connection could be regarded in this process, as previous school location databases have had information on computer availability in a school. It should be easier to provide schools that already have electricity and computers with access to the internet. Our third objective, and one which was requested by ITU, is to aggregate our understanding of internet connectivity on a school level up to a country level. While this might already exist for many countries, a national level aggregation will be helpful in countries where there are currently no surveys or established statistics on internet connectivity. Furthermore, a prediction from a robust and generalizable model has the potential to be even more accurate, or more complete than a national survey. Our model can establish a baseline metric for a country and build a greater understanding of countries that have low or high internet connectivity. The geographical nature of analysis also makes it possible to detect regional and local differences within countries themselves. Ultimately, we are contributing to the field of offline population research as well as global human development. Our model and approach offers fruitful insights into which features and models are most efficient in predicting internet connectivity. Hopefully, our results can be used by researchers and organizations. Within this site, you will find a documentation of our process and analysis as well as a discussion of our findings. Our aim is for this to be as reproducible as possible for other countries and we hope that it can be used for building a greater understanding of internet connectivity. While we link to scripts throughout, a full collection of scripts and documentation can be cloned via the GitHub repository here .","title":"Use Case"},{"location":"modapp/","text":"Model Application Thailand Our next big step was applying the best model to Thailand data. We were curious to apply the model as we were not sure that the same assumptions that are true for Brazil would hold true for Thailand. While the satellite data and vegetation may look the same, the national level economic and political indicators were not accounted for in the model. This is because, due to the project scope and capacity, we did not train multiple different national models. Had we had more time and data, perhaps this would have been an alternative route and we could have included some of this information. Instead, we trained a model exclusively on Brazil. For more discussion on future multi-national models, please see the conclusion. Therefore, the limitations for our model are rooted in basic assumptions that local areas can be comparable. A second limiting factor was the nature of Thailand data. We wanted to predict and evaluate the Thai schools in the same manner that we did for the Brazil schools. However, the survey data that served as ground truth for Brazil was on an enumeration area level while the survey data for Thailand was on a province area level (of which there are 77 in Thailand). These area units are not comparable and therefore made the evaluation for Thailand more complicated. Furthermore, due to their small size enumeration areas can be assumed to be more homogenous regarding demographics and also internet connectivtiy. As Thai provinces are much larger it seems to be unreasonable that one level of connectivity holds true for the entire province. If a province would consist of highly connected and highly offline areas, the data would reflect a moderate level of internet connectivity for the entire province, which would in reality reflect no area of the province. Below you can see the school area level predictions, which mostly appear to be on a reasonable level, though the absence of fine-grained ground truth data prevents model evaluation. For that reason we subsequently perform the only evaluating measures that the ground truth data allows for. First, we scale the school predictions up to a province level by calculating a population-weighted province connectivity share. We then compare these province-level values to the ground truth data visually and in a distribution plot. The large discrepancy between prediction and ground truth can potentially reflect upon our model and its questionable performance, but it also largely reflects on the raw survey data itself as we are skeptical of the amount of provinces that have 100% internet connectivity. Steps in our model application to new data. Please click here for a complete predict.py script. Click here for a Jupyter notebook with the XGBoost Predictions and its html equivalent. Using the predict_config, we load the Thailand data with the school points and the same predictors used by the original model. We then load the model from the provided model folder. The following code reloads the model and utilizes it to predict the connectivity on the Thailand dataset: After that, we examine the predictions on a map: Here are the maps that show the schools' predictions of relative online population from 0-1 in Thailand for all schools in Thailand provided by OpenStreetMaps in this case. Subsequently, we modify the map to only display schools predicted to be below 50% internet connectivity, by the best Random Forest model and XGBoost model. Both models predicted 97 schools where less than half of the individuals around it are connected, but the patterns of schools differ slightly. From a first visual inspection we could draw the conclusion, that high offline school areas are mostly predicted in more northern areas and areas close to the Thailand national borders. In order to compare our predictions to the ground truth, we aggregated the schools up to a province level as survey data was only provided on that level. This measure of evaluation proved challenging for a number of reasons as stated above. The following graphics compare predicted and survey data province level connectivity shares on a country map and in a distribution histogram: By visual inspection, we can see that the model predictions on a province level diverge greatly from the existing ground truth. While the predictions are roughly normally distributed across the provinces with a small range of predictions, the range of ground truth connectivity shares appears to be much broader. Therefore, we are uncertain about the ability for our Brazil model to accurately predict school areas' internet connectivity in Thailand. Nevertheless, it seems unreasonable that more than half of Thai provinces have a 100% connectivity rate which raises the uncertainty, whether the large average error of 0.35 was caused by the model or the ground truth data. Philippines We also were able to test this out on the Philippines. The Philippines had better data as their surveys were on an enumeration area level. Here are the results from our Philippines predictions. Further Application Configuration file For both the school priorization and the following aggregation, a specific congfiguration file (predict_config.yaml) was used. It contains case specific information like the data paths, predictor variable set, country name, country population, and steps on implementing the champion model in mlflow. Within this file, these characteristics can easily be updated. If, for instance, one trains a new model, the configuration file is where you can point to the location of the new model as opposed to in the corresponding notebooks or scripts. This creates more simplicity and minimizes human error. !! Pic of Configfile !! School Priorization Building on our school area predictions and additional information such as population or potential internet connectivity, we create a prioritization list of schools. This priorization can be changed based on various indicators like relative offline population or absolute offline population. Furthermore, if the data contains geographic information, the priorization list can be filtered by a specific federal state or to schools in rural areas. As a first step, the feature-engineered training dataset for the respective country (in the following example: Brazil) and the pickled champion model are loaded. The imported model is then applied to the second country's data and predicts online population for the schools featured in the dataset. Within this dataset, where schools are the rows, we can merge in more information on absolute population data of that school and information around the school's internet and computer availability. While population data is necessary to calculate the absolute offline population around a school, additional school information such as internet availability or pupil count might not be at hand for some countries. Therefore, that type of data is optional and not required for initial priorization. Since our model was not restricted to predict only values between 0 and 1, (for example it predicted values above 1 and below 0) we first standardized predicted values to be between these boundaries. Secondly, we multiply the prediction of online population share by the population count, which yields the estimated absolute online population around a school. The corresponding offline population is calculated by taking 1 - \"online population share\" and the multiplying this value with the population count. At this point, we've finished with the basic arithmetical steps and can create our custom priorization list. In this example, we first export the list of schools by absolute offline population, from greatest to smallest. In theory, connecting the first school in this list would potentially benefit the largest number of individuals in the school sample. We export additional information provided in the school data such as the school's name to facilitate use of the list. As our data for Brazil contains additional information (e.g. computer and internet availability), we not only add these variables to our exported file, but we also subset our schools to prioritize using these. It makes sense to exclude schools that, according to the UNICEF school data, already have internet access. Therefore, the second file lists only the offline schools ranked by the absolute offline population around it. The third subsetting step was to exclude the 10th population number decile of the sample, i.e. the outlying 10% of schools, that have the largest number of population around them. This rather exploratory step was done to investigate whether some schools are highly prioritized solely due to their high population numbers. Excluding the highest populated areas (in most cases large metropolitan areas) can lead towards the potentially less obvious hubs of offline population. For each of the priorization lists, a graphic that maps the schools and depicts the offline population is provided. Country-level Aggregation A further step of model application was the aggregation to the country level. However, estimating the mere average of online population shares is not possible in this case, since it would weight each enumeration area (or other unit of geographic aggregation) equally. An enumeration area with 25 inhabitants would contribute as much to the national average as an enumeration area with 25.000 people. #are we sure this is how enumeration areas are created?! Therefore, the national average is calculated slightly different. We sum up the previously calculated absolute online population and sum up the total population in our sample. If our enumeration area sample is representative for the whole country, dividing the total online population by the total population (both in sample) would yield a representative national level connectivity share. Ultimately, this proportion can be multiplied with the national population in order to get the absolute number of people connected to the internet. As a robustness check, the same calculations are then conducted using the ground truth connectivity data. If the required data is available, the aggregation can of course also be done to a province, federal state or other geographical level. Population data remarks Generally, some remarks regarding the absolute population data should be made and considered by users. For the priorization and the country level aggregation, the absolute number has to be treated cautiously due to school area overlap. In this exemplary priorization list we can see that the first 6 schools have the same ground truth connectivtity level (\"offline_g\"). This indicates that these schools are all located in the same enumeration area (you can also tell from the geographic coordinates of the school location). The point from this list is that the radius around each school is most likely going to overlap with another school in an urban area and therefore individuals within this overlap will be counted more than once in the population numbers. While the number of roughly 50,000 people potentially reached with connecting the one specific school is accurate, we must bear in mind, that connecting 5 schools each with an absolute population of 50,000 people will not result in connecting 250,000 people to the internet because of the population overlap issue. Additionally, once the first school is connected to the internet, the priorization list will be altered since some individuals will already obtain internet through the first school leaving other schools on the list as a lower priority for connection (since prioritization is based exclusively on absolute population assisted). Due to the overlap of school areas, adding up the population numbers of the enumeration areas will always overestimate the total number of indiviudals featured in our analysis, as many will be counted more than once. It therefore prevents understanding an exact amount of individuals that can be connected to the internet on any geographic level. If researchers and organizations are aware of this and treat the population data cautiously, the list is a great resource. Even though densely populated areas like Sao Paolo will have school area (and therefore population data) overlap, the model can detect this enumeration area/neighborhood as a zone that would benefit from being connected. Providing one school with internet access in a densely populated area will in any case most likely not suffice in providing thousands of people with internet. Thus, it is a reasonable suggestion to connect multiple schools in the same area to the internet, even though the absolute population it will be getting online is somewhat skewed.","title":"Model Application"},{"location":"modapp/#model-application","text":"","title":"Model Application"},{"location":"modapp/#thailand","text":"Our next big step was applying the best model to Thailand data. We were curious to apply the model as we were not sure that the same assumptions that are true for Brazil would hold true for Thailand. While the satellite data and vegetation may look the same, the national level economic and political indicators were not accounted for in the model. This is because, due to the project scope and capacity, we did not train multiple different national models. Had we had more time and data, perhaps this would have been an alternative route and we could have included some of this information. Instead, we trained a model exclusively on Brazil. For more discussion on future multi-national models, please see the conclusion. Therefore, the limitations for our model are rooted in basic assumptions that local areas can be comparable. A second limiting factor was the nature of Thailand data. We wanted to predict and evaluate the Thai schools in the same manner that we did for the Brazil schools. However, the survey data that served as ground truth for Brazil was on an enumeration area level while the survey data for Thailand was on a province area level (of which there are 77 in Thailand). These area units are not comparable and therefore made the evaluation for Thailand more complicated. Furthermore, due to their small size enumeration areas can be assumed to be more homogenous regarding demographics and also internet connectivtiy. As Thai provinces are much larger it seems to be unreasonable that one level of connectivity holds true for the entire province. If a province would consist of highly connected and highly offline areas, the data would reflect a moderate level of internet connectivity for the entire province, which would in reality reflect no area of the province. Below you can see the school area level predictions, which mostly appear to be on a reasonable level, though the absence of fine-grained ground truth data prevents model evaluation. For that reason we subsequently perform the only evaluating measures that the ground truth data allows for. First, we scale the school predictions up to a province level by calculating a population-weighted province connectivity share. We then compare these province-level values to the ground truth data visually and in a distribution plot. The large discrepancy between prediction and ground truth can potentially reflect upon our model and its questionable performance, but it also largely reflects on the raw survey data itself as we are skeptical of the amount of provinces that have 100% internet connectivity. Steps in our model application to new data. Please click here for a complete predict.py script. Click here for a Jupyter notebook with the XGBoost Predictions and its html equivalent. Using the predict_config, we load the Thailand data with the school points and the same predictors used by the original model. We then load the model from the provided model folder. The following code reloads the model and utilizes it to predict the connectivity on the Thailand dataset: After that, we examine the predictions on a map: Here are the maps that show the schools' predictions of relative online population from 0-1 in Thailand for all schools in Thailand provided by OpenStreetMaps in this case. Subsequently, we modify the map to only display schools predicted to be below 50% internet connectivity, by the best Random Forest model and XGBoost model. Both models predicted 97 schools where less than half of the individuals around it are connected, but the patterns of schools differ slightly. From a first visual inspection we could draw the conclusion, that high offline school areas are mostly predicted in more northern areas and areas close to the Thailand national borders. In order to compare our predictions to the ground truth, we aggregated the schools up to a province level as survey data was only provided on that level. This measure of evaluation proved challenging for a number of reasons as stated above. The following graphics compare predicted and survey data province level connectivity shares on a country map and in a distribution histogram: By visual inspection, we can see that the model predictions on a province level diverge greatly from the existing ground truth. While the predictions are roughly normally distributed across the provinces with a small range of predictions, the range of ground truth connectivity shares appears to be much broader. Therefore, we are uncertain about the ability for our Brazil model to accurately predict school areas' internet connectivity in Thailand. Nevertheless, it seems unreasonable that more than half of Thai provinces have a 100% connectivity rate which raises the uncertainty, whether the large average error of 0.35 was caused by the model or the ground truth data.","title":"Thailand"},{"location":"modapp/#philippines","text":"We also were able to test this out on the Philippines. The Philippines had better data as their surveys were on an enumeration area level. Here are the results from our Philippines predictions.","title":"Philippines"},{"location":"modapp/#further-application","text":"","title":"Further Application"},{"location":"modapp/#configuration-file","text":"For both the school priorization and the following aggregation, a specific congfiguration file (predict_config.yaml) was used. It contains case specific information like the data paths, predictor variable set, country name, country population, and steps on implementing the champion model in mlflow. Within this file, these characteristics can easily be updated. If, for instance, one trains a new model, the configuration file is where you can point to the location of the new model as opposed to in the corresponding notebooks or scripts. This creates more simplicity and minimizes human error. !! Pic of Configfile !!","title":"Configuration file"},{"location":"modapp/#school-priorization","text":"Building on our school area predictions and additional information such as population or potential internet connectivity, we create a prioritization list of schools. This priorization can be changed based on various indicators like relative offline population or absolute offline population. Furthermore, if the data contains geographic information, the priorization list can be filtered by a specific federal state or to schools in rural areas. As a first step, the feature-engineered training dataset for the respective country (in the following example: Brazil) and the pickled champion model are loaded. The imported model is then applied to the second country's data and predicts online population for the schools featured in the dataset. Within this dataset, where schools are the rows, we can merge in more information on absolute population data of that school and information around the school's internet and computer availability. While population data is necessary to calculate the absolute offline population around a school, additional school information such as internet availability or pupil count might not be at hand for some countries. Therefore, that type of data is optional and not required for initial priorization. Since our model was not restricted to predict only values between 0 and 1, (for example it predicted values above 1 and below 0) we first standardized predicted values to be between these boundaries. Secondly, we multiply the prediction of online population share by the population count, which yields the estimated absolute online population around a school. The corresponding offline population is calculated by taking 1 - \"online population share\" and the multiplying this value with the population count. At this point, we've finished with the basic arithmetical steps and can create our custom priorization list. In this example, we first export the list of schools by absolute offline population, from greatest to smallest. In theory, connecting the first school in this list would potentially benefit the largest number of individuals in the school sample. We export additional information provided in the school data such as the school's name to facilitate use of the list. As our data for Brazil contains additional information (e.g. computer and internet availability), we not only add these variables to our exported file, but we also subset our schools to prioritize using these. It makes sense to exclude schools that, according to the UNICEF school data, already have internet access. Therefore, the second file lists only the offline schools ranked by the absolute offline population around it. The third subsetting step was to exclude the 10th population number decile of the sample, i.e. the outlying 10% of schools, that have the largest number of population around them. This rather exploratory step was done to investigate whether some schools are highly prioritized solely due to their high population numbers. Excluding the highest populated areas (in most cases large metropolitan areas) can lead towards the potentially less obvious hubs of offline population. For each of the priorization lists, a graphic that maps the schools and depicts the offline population is provided.","title":"School Priorization"},{"location":"modapp/#country-level-aggregation","text":"A further step of model application was the aggregation to the country level. However, estimating the mere average of online population shares is not possible in this case, since it would weight each enumeration area (or other unit of geographic aggregation) equally. An enumeration area with 25 inhabitants would contribute as much to the national average as an enumeration area with 25.000 people. #are we sure this is how enumeration areas are created?! Therefore, the national average is calculated slightly different. We sum up the previously calculated absolute online population and sum up the total population in our sample. If our enumeration area sample is representative for the whole country, dividing the total online population by the total population (both in sample) would yield a representative national level connectivity share. Ultimately, this proportion can be multiplied with the national population in order to get the absolute number of people connected to the internet. As a robustness check, the same calculations are then conducted using the ground truth connectivity data. If the required data is available, the aggregation can of course also be done to a province, federal state or other geographical level.","title":"Country-level Aggregation"},{"location":"modapp/#population-data-remarks","text":"Generally, some remarks regarding the absolute population data should be made and considered by users. For the priorization and the country level aggregation, the absolute number has to be treated cautiously due to school area overlap. In this exemplary priorization list we can see that the first 6 schools have the same ground truth connectivtity level (\"offline_g\"). This indicates that these schools are all located in the same enumeration area (you can also tell from the geographic coordinates of the school location). The point from this list is that the radius around each school is most likely going to overlap with another school in an urban area and therefore individuals within this overlap will be counted more than once in the population numbers. While the number of roughly 50,000 people potentially reached with connecting the one specific school is accurate, we must bear in mind, that connecting 5 schools each with an absolute population of 50,000 people will not result in connecting 250,000 people to the internet because of the population overlap issue. Additionally, once the first school is connected to the internet, the priorization list will be altered since some individuals will already obtain internet through the first school leaving other schools on the list as a lower priority for connection (since prioritization is based exclusively on absolute population assisted). Due to the overlap of school areas, adding up the population numbers of the enumeration areas will always overestimate the total number of indiviudals featured in our analysis, as many will be counted more than once. It therefore prevents understanding an exact amount of individuals that can be connected to the internet on any geographic level. If researchers and organizations are aware of this and treat the population data cautiously, the list is a great resource. Even though densely populated areas like Sao Paolo will have school area (and therefore population data) overlap, the model can detect this enumeration area/neighborhood as a zone that would benefit from being connected. Providing one school with internet access in a densely populated area will in any case most likely not suffice in providing thousands of people with internet. Thus, it is a reasonable suggestion to connect multiple schools in the same area to the internet, even though the absolute population it will be getting online is somewhat skewed.","title":"Population data remarks"},{"location":"model/","text":"Modeling Section: The model we need to train is a regression model as we are attempting to predict a number between 0 and 1 of internet connectivity. A result or prediction of 0 means that of the households surveyed (about 11), no households in the enumeration area stated that they had access to internet. A result or prediction of 1 means that every household surveyed in the enumeration area had access to internet. Most responses fell on a scale between 0 and 1, indicating that some but not all families had internet access. Later on, we attempted to turn this into a classification problem to check our work but it did not provide any higher accuracy. Training Set EDA We also did some Exploratory Data Analysis once our training dataset was created. Click Here for the full notebook of explanatory visualizations. Click here for the Jupyter Notebook .ipynb file. Mlflow Set-up (Optional) In order to track our models, we set up autologging in mlflow. Mlflow is an exciting and experimental way of logging models. We set up our model training so that our python script for each model would create a new experiment for each run, it would log each of our model parameters when we did hyperparameter tuning and then log the best parameter at the top. In this way we were able to compare the various parameters logged in each run to determine how to change the grid space of the hyperparameters. We also were then able to compare models to each other. Within mlflow, we also logged the predictors for each run and the requirements for packages and dependencies to run. Each run also logs the best model as an artifact, so one can easily take the model and apply it to new data. We are including both the best model logged, as well as each run, here in order to make this as reproducible as possible. Below you can see a screenshot of a mlflow which logs our best runs, with our best hyperparameters and using our custom metric for evaluation. On the side, you can also see the list of other experiments we ran with different models. ``` #### mlflow setup #### # save runs mlflow.set_tracking_uri(\"file:///files/mlruns\") mlflow.tracking.get_tracking_uri() #Naming the set_experiment dt = date.today().strftime('%d/%m/%Y') experiment_name = dt + model_config['meta']['experiment_name'] mlflow.set_experiment(experiment_name) mlflow_client = mlflow.tracking.MlflowClient() experiment_id = mlflow_client.get_experiment_by_name(experiment_name).experiment_id ``` Here you can see the simplicity of reload the model artifact later on and applying on new data: Model Configuration Once we have mlflow set up and our model_config.yaml file set up, we can run many different experiments using our .py scripts by changing a few things within our yaml file. Click here to see the full yaml file. Below you can also see how it was set up. We use this to steer our scripts and set our parameters. We set up the input data at the top which is our training data, then label the target and predictor variables as well as the name of the experiment and a brief description in run_name. Under the parameters section, we set parameters like test size (which is crucial), the amount of cross validation folds to do, the number of iterations and the threshold for our custom metric. The threshold tells the model which percent of schools with low internet connectivity to focus on. Then within parameters, there are different sections based on what type of model you might decide to run. Our .yaml file contains parameters for grid search within Random Forest, LightGBM and XGBoost. In our current scripts, we've commented out the mlflow logging for hyperparameter tuning because it takes a long time to log and towards the end we just wanted to log our best models. Model Training We tried out 7 different model classes and ran over 100 experiments each containing 20 or more runs that tried various parameters in order to determine which model had the best accuracy. We experimented with various parameters, as well as different combinations of predictors. Below is the final list of predictors we used and a heat map displaying their collinearity. As you can see, there is not high multi-collinearity among our predictors except with the mean global human modification and the mean average radiance. However, we felt both predictors were important and had high feature importance in the model so we decided to keep both in. In this figure, one can see the correlation between predictors and our target variable. Predictors like the global human modification and average radiance have strong correlation. Another way that we improved accuracy was by building a custom metric in order to score both our test set within our cross validation and our final holdout set. The metric calculates errors specifically by taking the prediction below .3 (or another threshold, we also experimented with .5) subtracting that from the ground truth below .3 (or another threshold), taking the absolute value and then returning the average of all those errors. Below please find a code snippet of our custom metric. #Create custom scoring def custom_eval_metric(y_true, y_pred): errors_low = abs(y_pred[y_pred<0.3] - np.asarray(y_true[y_pred<0.3]).flatten()) return np.mean(errors_low) custom_scorer = make_scorer(custom_eval_metric, greater_is_better = False) # define grid search search = GridSearchCV(model, parameters, scoring = custom_scorer, cv = inner_cv , refit=True, verbose = 2) We built this as we understood that it was more important to have better accuracy on schools with lower internet connectivity than higher connectivity. Before insitituting the custom metric, our models were good with predicting the average values, but they did poorly at either end of the spectrum and particularly on the low values. In order to remedy this issue, we first dropped any rows that had an internet connectivity of zero (there were 23 of them). We dropped the zero's because our project partners informed us that they were most likely due to incomplete data and because they skewed our results. Because there were only 23 of them, we felt it did not impact the data class balancing. Secondly, we instituted our custom metric which trained the model to minimize the error score under the .3 level of prediction. Within our scripts, we offer two ways of doing cross validation. One is by grid search which searches through every combination of the hyperparameter grid space to find the best combination. The other format is Randomized Grid Search which searches through a random combination and is steered by the number of iterations (or combinations to test out) given to it in the config file. As we have tested all the hyperparameters, the current grid space is much smaller than prior and we have chose to include gridsearch cv with randomized cv commented out in case one wants to add more parameters and tune themselves. The resulting champion out of over 2000 models was XGBoost with an average error of .06 and specifically for under the .3 threshold, had an average error of .05. This means that for schools that are predicted to be below 30%, we can trust the model's predictions, as on average the predictions are only off by 5 percentage points from the ground truth value. Below, you can see the list of all the model classes we tried. Feel free to try out running these models yourselves or reading the code by clicking on the hyper linked script. There is further documentation within each script on how it runs, and how it works with mlflow logging. Linear Regression Python script with Mlflow Random Forest HTML File Jupyter Notebook Python Script with Mlflow Python script without Mlflow XGBoost HTML File Jupyter Notebook #this is not correct Python Script with Mlflow Python script without Mlflow LightGBM HTML File Jupyter Notebook Python Script with Mlflow SVM Python Script with Mlflow Neural Net Python Script with Mlflow Random Forest Classifier HTML File Jupyter Notebook Model Evaluation and Results Below we see a comparison of all the models. It is clear that Random Forest and XGBoost both have the lowest average error among all the models, therefore they are the winners. Click on this link to see a notebook with the model comparisons. Click here for the HTML version. As you can see from the above graph, our winning model was the XGboost model which produced an error of .06 and a low average error of .05 with the hyper parameters of: eta: .2, max_depth: 9, n_estimators: 550. Click on this link for the notebook with the Random Forest Predictions and click on this link for the notebook with the XGBoost Predictions . Here is a map of our predictions for schools within Brazil. Figure 1 displays the location for all the schools were the ground truth is less than 30% connected to the internet. There are 69 schools in Brazil that have less than 30% internet connectivity. Figure 2 shows the errors in schools where the prediction is less than 30% connected to the internet. While we can see that there are fewer schools that are predicted than that exist, we can trust that our predictions are correct, as the error score is low. This map was made using the Random Forest model which predicts 14 schools. The XGBoost model predicts 29 schools below 30%. Additionally, our predicted schools match up with our ground truth schools. In Figure 3, we see the predictions for all the schools in the test set mapped out. This gives us an understanding of where the higher and lower connected schools are located regionally. It appears that the higher connected schools are on the coast (the yellows and light greens) while the lower connected schools are located more inland. In Figure 4, we see the errors mapped out for the schools in the test set. As we can see most schools have a low error score, which means we can mostly trust the predictions. The schools with higher error scores are also the schools that have less connectivity, which provides even more motivation to use our custom metric as we want to focus on having a lower error score for schools that are less connected. Thus the 14 schools depicted in Figure 2 are the ones that one could prioritize to connect. We also see that our predictions closely mirror the ground truth within the country, as well as an external data source titled Digital 2021: Brazil. Thus we can trust that our model performs well on Brazilian school data. This graph compares predictions to reality. We can see that the points are quite close to the line except within the lower range. Then we see the residuals compared to reality. This is promising as most residuals hug tightly to the line except for the ones at the very low and high end. Lastly, we also see the comparison of distributions between reality and predictions. While the predictions are a bit higher, the overall curves generally follow each other. Model Interpretation As part of our winning models, we wanted to see which predictors had high feature importance within the model. Below, is the graph for both Random Forest and XGBoost feature importances. As one can see, the highest feature importances are the nighttime average radiance predictor and the Facebook monthly active users. Here are the examinations of the shapely values for feature importances. @Jacob or Utku to put in pics -Shaply values overall -for very low and high error -individual shaply for one school -line/scatter feature importances from utku?","title":"Modeling"},{"location":"model/#modeling-section","text":"The model we need to train is a regression model as we are attempting to predict a number between 0 and 1 of internet connectivity. A result or prediction of 0 means that of the households surveyed (about 11), no households in the enumeration area stated that they had access to internet. A result or prediction of 1 means that every household surveyed in the enumeration area had access to internet. Most responses fell on a scale between 0 and 1, indicating that some but not all families had internet access. Later on, we attempted to turn this into a classification problem to check our work but it did not provide any higher accuracy.","title":"Modeling Section:"},{"location":"model/#training-set-eda","text":"We also did some Exploratory Data Analysis once our training dataset was created. Click Here for the full notebook of explanatory visualizations. Click here for the Jupyter Notebook .ipynb file.","title":"Training Set EDA"},{"location":"model/#mlflow-set-up-optional","text":"In order to track our models, we set up autologging in mlflow. Mlflow is an exciting and experimental way of logging models. We set up our model training so that our python script for each model would create a new experiment for each run, it would log each of our model parameters when we did hyperparameter tuning and then log the best parameter at the top. In this way we were able to compare the various parameters logged in each run to determine how to change the grid space of the hyperparameters. We also were then able to compare models to each other. Within mlflow, we also logged the predictors for each run and the requirements for packages and dependencies to run. Each run also logs the best model as an artifact, so one can easily take the model and apply it to new data. We are including both the best model logged, as well as each run, here in order to make this as reproducible as possible. Below you can see a screenshot of a mlflow which logs our best runs, with our best hyperparameters and using our custom metric for evaluation. On the side, you can also see the list of other experiments we ran with different models. ``` #### mlflow setup #### # save runs mlflow.set_tracking_uri(\"file:///files/mlruns\") mlflow.tracking.get_tracking_uri() #Naming the set_experiment dt = date.today().strftime('%d/%m/%Y') experiment_name = dt + model_config['meta']['experiment_name'] mlflow.set_experiment(experiment_name) mlflow_client = mlflow.tracking.MlflowClient() experiment_id = mlflow_client.get_experiment_by_name(experiment_name).experiment_id ``` Here you can see the simplicity of reload the model artifact later on and applying on new data:","title":"Mlflow Set-up (Optional)"},{"location":"model/#model-configuration","text":"Once we have mlflow set up and our model_config.yaml file set up, we can run many different experiments using our .py scripts by changing a few things within our yaml file. Click here to see the full yaml file. Below you can also see how it was set up. We use this to steer our scripts and set our parameters. We set up the input data at the top which is our training data, then label the target and predictor variables as well as the name of the experiment and a brief description in run_name. Under the parameters section, we set parameters like test size (which is crucial), the amount of cross validation folds to do, the number of iterations and the threshold for our custom metric. The threshold tells the model which percent of schools with low internet connectivity to focus on. Then within parameters, there are different sections based on what type of model you might decide to run. Our .yaml file contains parameters for grid search within Random Forest, LightGBM and XGBoost. In our current scripts, we've commented out the mlflow logging for hyperparameter tuning because it takes a long time to log and towards the end we just wanted to log our best models.","title":"Model Configuration"},{"location":"model/#model-training","text":"We tried out 7 different model classes and ran over 100 experiments each containing 20 or more runs that tried various parameters in order to determine which model had the best accuracy. We experimented with various parameters, as well as different combinations of predictors. Below is the final list of predictors we used and a heat map displaying their collinearity. As you can see, there is not high multi-collinearity among our predictors except with the mean global human modification and the mean average radiance. However, we felt both predictors were important and had high feature importance in the model so we decided to keep both in. In this figure, one can see the correlation between predictors and our target variable. Predictors like the global human modification and average radiance have strong correlation. Another way that we improved accuracy was by building a custom metric in order to score both our test set within our cross validation and our final holdout set. The metric calculates errors specifically by taking the prediction below .3 (or another threshold, we also experimented with .5) subtracting that from the ground truth below .3 (or another threshold), taking the absolute value and then returning the average of all those errors. Below please find a code snippet of our custom metric. #Create custom scoring def custom_eval_metric(y_true, y_pred): errors_low = abs(y_pred[y_pred<0.3] - np.asarray(y_true[y_pred<0.3]).flatten()) return np.mean(errors_low) custom_scorer = make_scorer(custom_eval_metric, greater_is_better = False) # define grid search search = GridSearchCV(model, parameters, scoring = custom_scorer, cv = inner_cv , refit=True, verbose = 2) We built this as we understood that it was more important to have better accuracy on schools with lower internet connectivity than higher connectivity. Before insitituting the custom metric, our models were good with predicting the average values, but they did poorly at either end of the spectrum and particularly on the low values. In order to remedy this issue, we first dropped any rows that had an internet connectivity of zero (there were 23 of them). We dropped the zero's because our project partners informed us that they were most likely due to incomplete data and because they skewed our results. Because there were only 23 of them, we felt it did not impact the data class balancing. Secondly, we instituted our custom metric which trained the model to minimize the error score under the .3 level of prediction. Within our scripts, we offer two ways of doing cross validation. One is by grid search which searches through every combination of the hyperparameter grid space to find the best combination. The other format is Randomized Grid Search which searches through a random combination and is steered by the number of iterations (or combinations to test out) given to it in the config file. As we have tested all the hyperparameters, the current grid space is much smaller than prior and we have chose to include gridsearch cv with randomized cv commented out in case one wants to add more parameters and tune themselves. The resulting champion out of over 2000 models was XGBoost with an average error of .06 and specifically for under the .3 threshold, had an average error of .05. This means that for schools that are predicted to be below 30%, we can trust the model's predictions, as on average the predictions are only off by 5 percentage points from the ground truth value. Below, you can see the list of all the model classes we tried. Feel free to try out running these models yourselves or reading the code by clicking on the hyper linked script. There is further documentation within each script on how it runs, and how it works with mlflow logging. Linear Regression Python script with Mlflow Random Forest HTML File Jupyter Notebook Python Script with Mlflow Python script without Mlflow XGBoost HTML File Jupyter Notebook #this is not correct Python Script with Mlflow Python script without Mlflow LightGBM HTML File Jupyter Notebook Python Script with Mlflow SVM Python Script with Mlflow Neural Net Python Script with Mlflow Random Forest Classifier HTML File Jupyter Notebook","title":"Model Training"},{"location":"model/#model-evaluation-and-results","text":"Below we see a comparison of all the models. It is clear that Random Forest and XGBoost both have the lowest average error among all the models, therefore they are the winners. Click on this link to see a notebook with the model comparisons. Click here for the HTML version. As you can see from the above graph, our winning model was the XGboost model which produced an error of .06 and a low average error of .05 with the hyper parameters of: eta: .2, max_depth: 9, n_estimators: 550. Click on this link for the notebook with the Random Forest Predictions and click on this link for the notebook with the XGBoost Predictions . Here is a map of our predictions for schools within Brazil. Figure 1 displays the location for all the schools were the ground truth is less than 30% connected to the internet. There are 69 schools in Brazil that have less than 30% internet connectivity. Figure 2 shows the errors in schools where the prediction is less than 30% connected to the internet. While we can see that there are fewer schools that are predicted than that exist, we can trust that our predictions are correct, as the error score is low. This map was made using the Random Forest model which predicts 14 schools. The XGBoost model predicts 29 schools below 30%. Additionally, our predicted schools match up with our ground truth schools. In Figure 3, we see the predictions for all the schools in the test set mapped out. This gives us an understanding of where the higher and lower connected schools are located regionally. It appears that the higher connected schools are on the coast (the yellows and light greens) while the lower connected schools are located more inland. In Figure 4, we see the errors mapped out for the schools in the test set. As we can see most schools have a low error score, which means we can mostly trust the predictions. The schools with higher error scores are also the schools that have less connectivity, which provides even more motivation to use our custom metric as we want to focus on having a lower error score for schools that are less connected. Thus the 14 schools depicted in Figure 2 are the ones that one could prioritize to connect. We also see that our predictions closely mirror the ground truth within the country, as well as an external data source titled Digital 2021: Brazil. Thus we can trust that our model performs well on Brazilian school data. This graph compares predictions to reality. We can see that the points are quite close to the line except within the lower range. Then we see the residuals compared to reality. This is promising as most residuals hug tightly to the line except for the ones at the very low and high end. Lastly, we also see the comparison of distributions between reality and predictions. While the predictions are a bit higher, the overall curves generally follow each other.","title":"Model Evaluation and Results"},{"location":"model/#model-interpretation","text":"As part of our winning models, we wanted to see which predictors had high feature importance within the model. Below, is the graph for both Random Forest and XGBoost feature importances. As one can see, the highest feature importances are the nighttime average radiance predictor and the Facebook monthly active users. Here are the examinations of the shapely values for feature importances. @Jacob or Utku to put in pics -Shaply values overall -for very low and high error -individual shaply for one school -line/scatter feature importances from utku?","title":"Model Interpretation"},{"location":"Images/Images/","text":"","title":"Images"}]}